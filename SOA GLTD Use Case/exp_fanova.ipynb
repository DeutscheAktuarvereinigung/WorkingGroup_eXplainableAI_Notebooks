{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Simon-Style -->\n",
    "<p style=\"font-size:19px; text-align:left; margin-top:    15px;\"><i>German Association of Actuaries (DAV) — Working Group \"Explainable Artificial Intelligence\"</i></p>\n",
    "<p style=\"font-size:25px; text-align:left; margin-bottom: 15px\"><b>Use Case SOA GLTD Experience Study:<br>\n",
    "USE CASE GLTD - FANOVA with dependent categorical inputs\n",
    "</b></p>\n",
    "<p style=\"font-size:19px; text-align:left; margin-bottom: 15px; margin-bottom: 15px\">Guido Grützner (<a href=\"mailto:guido.gruetzner@quantakt.com\">guido.gruetzner@quantakt.com</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a variant of the functional ANOVA decomposition for functions where all inputs are categorical with arbitrary dependence between them. In particular\n",
    "* It introduces the first Sobol index as a measure of variable importance, which is intuitive and easy to compute .\n",
    "* It calculates a total interaction index, which allows splitting the amount of variance explained between main effects and interactions.\n",
    "* It gives full details on pairwise interactions, i.e. second order Sobol indices. \n",
    "\n",
    "Using the decomposition of main effects and interaction, we can provide an in-depth explanation for differences between models with interaction (e.g. boosted tree models) and models without interactions (e-g. main effects GLMs). \n",
    "\n",
    "All calculations are based on conditional expectations derived from the original data distribution. A conditional expectation with respect to an input variable, is called the main effects function with respect to that variable. Main effect functions are the central tool and target of the analysis in this notebook. One major difference between the approach here, and traditional statistics, such Permutation Feature Importance or Friedman's H-statistic, is the use of main effects instead of partial dependence functions. If all inputs are stochastically independent, main effects and partial dependence functions are identical, but, in general, they are (very) different. The use of true conditional expectations is only possible for categorical inputs. Since the conditioning set of a numerical variable has measure zero, it is not possible or at least very hard to estimate conditional expectations from a sample. But the underlying distribution of categorical variables is discrete, and the empirical conditional expectation can be found by a simple and very fast grouping operation. The approach has several advantages over the traditional methods, which assume independent margins: \n",
    "* No evaluations on \"impossible data\" and no distortion of probabilities in case of dependence.\n",
    "* In addition to providing statistics for models, the statistics can also be calculated just using the raw data.\n",
    "* Estimates are analytically derived from the original dataset and not by resampling of the data. This avoids resampling error and allows much faster execution speed.\n",
    "\n",
    "To apply these methods to the GLTD, the numerical inputs have to be transformed into categorical inputs, i.e. discretized. Even though this results in some loss of accuracy, the advantages stated above are so substantial, that they outweigh the disadvantage discrtetization. This notebook uses a very simple discretization scheme, which most certainly can be improved.\n",
    "\n",
    "Evaluation of the second order indices requires generalizations of the original FANOVA procedures to properly account for dependencies. These modifications are explained in more detail in the accompanying notebook \"edu_Hcorr.ipynb\".\n",
    "\n",
    "Depending on the size of the dataset (which can be adjusted using the parameter `pct` in the second initialization block) the notebook may take several minutes to run. But this is only due to the time required to fit the three models, which are gradient boosted tree with interactions (\"GBT_with\") the same model but without interactions (\"GBT_wo\") and a main effects GLM (\"GLM\"). The subsequent calculations of the statistics take only a few seconds. This is possible, in spite of the serious size and complexity of the dataset with 21 input variables, cardinalities of the categorical variables up to 60 and roughly 6.4 million observations in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:08:20.410866Z",
     "iopub.status.busy": "2024-07-29T20:08:20.409867Z",
     "iopub.status.idle": "2024-07-29T20:08:21.355691Z",
     "shell.execute_reply": "2024-07-29T20:08:21.355691Z",
     "shell.execute_reply.started": "2024-07-29T20:08:20.410866Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from glum import GeneralizedLinearRegressor\n",
    "\n",
    "from IPython.display import display_html\n",
    "\n",
    "# adjust accordingly, more CPUs is faster but then script may block PC\n",
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), '../report versions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import gltd_utilities\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adapt the path for the data file in the call of `load_gltd_data`, if necessary.\n",
    "* Adapt pct to your requirements for anything between  $0.05\\leq pct\\leq1$. \n",
    "* Input 1 uses all data available, lower numbers the respective fraction. Below a value of 0.05, predictions become somewhat volatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:08:21.356666Z",
     "iopub.status.busy": "2024-07-29T20:08:21.356666Z",
     "iopub.status.idle": "2024-07-29T20:08:22.492621Z",
     "shell.execute_reply": "2024-07-29T20:08:22.492621Z",
     "shell.execute_reply.started": "2024-07-29T20:08:21.356666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'129870251340744769036896803466667540219'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.time()\n",
    "(X, Y, ID, nm_cat, nm_num, seed, rng) = gltd_utilities.load_gltd_data(\n",
    "                                        \"d:/tmp/GLTD data/\", pct=0.3)\n",
    "for vnm in nm_cat:\n",
    "    X[vnm] = X[vnm].cat.remove_unused_categories()\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization of numerical inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T10:44:46.538677Z",
     "iopub.status.busy": "2024-07-27T10:44:46.538677Z",
     "iopub.status.idle": "2024-07-27T10:44:46.549501Z",
     "shell.execute_reply": "2024-07-27T10:44:46.549501Z",
     "shell.execute_reply.started": "2024-07-27T10:44:46.538677Z"
    }
   },
   "source": [
    "As discussed in the introduction, the numerical inputs have to be transformed into categorical variables. Here, no effort was expended to have an efficient encoding, instead the most simple approach was chosen, binning into 10 equal exposure buckets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:08:22.493630Z",
     "iopub.status.busy": "2024-07-29T20:08:22.493630Z",
     "iopub.status.idle": "2024-07-29T20:08:35.521786Z",
     "shell.execute_reply": "2024-07-29T20:08:35.518692Z",
     "shell.execute_reply.started": "2024-07-29T20:08:22.493630Z"
    }
   },
   "outputs": [],
   "source": [
    "# recode SSA\n",
    "tmp = (X['Original_Social_Security_Award_Status'].astype(str) \n",
    "        + \"_\" + X['Updated_Social_Security_Award_Status'].astype(str))\n",
    "X[\"Combined_SSA\"] = tmp.astype(\"category\")\n",
    "X.drop(['Original_Social_Security_Award_Status',\n",
    "'Updated_Social_Security_Award_Status'], axis=1, inplace=True)\n",
    "\n",
    "# bin into equal exposure buckets\n",
    "nbucket = 10\n",
    "\n",
    "Xbin = X\n",
    "for vnm in nm_num:\n",
    "    Xbin[vnm] = pd.qcut(X[vnm], nbucket, duplicates=\"drop\")\n",
    "\n",
    "# turn IntervalIndex into standard categorical one\n",
    "# required to enable broadcasting later on\n",
    "# I am not 100% sure why, but this is required\n",
    "nm_var = Xbin.columns.to_list()\n",
    "for vnm in nm_var:\n",
    "    Xbin[vnm]=Xbin[vnm].astype(str)\n",
    "    Xbin[vnm]=Xbin[vnm].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the three models (\"GBT_with\", \"GBT_wo\", \"GLM\") on non-aggregated data. This is necessary to ensure that observations are iid in particular that each input in the dataset has the same probability. Since the properties and qualities of the models have been discussed in other notebooks for this use case, we just fit the models and perform no train/test split or other evaluations.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:08:35.524318Z",
     "iopub.status.busy": "2024-07-29T20:08:35.523300Z",
     "iopub.status.idle": "2024-07-29T20:11:38.363518Z",
     "shell.execute_reply": "2024-07-29T20:11:38.363518Z",
     "shell.execute_reply.started": "2024-07-29T20:08:35.524318Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain = Xbin\n",
    "ytrain = Y\n",
    "\n",
    "sammler = []\n",
    "# GBT        \n",
    "md = HistGradientBoostingClassifier(\n",
    "        interaction_cst = None,\n",
    "        categorical_features=\"from_dtype\",\n",
    "        max_iter=1000,\n",
    "        learning_rate=0.025,\n",
    "        max_leaf_nodes=100,\n",
    "        random_state=rng.integers(low=0, high=1000))\n",
    "md.fit(xtrain, ytrain)\n",
    "sammler.append(pd.Series(md.predict_proba(xtrain)[:,1], index=xtrain.index, name=\"GBT_with\"))\n",
    "\n",
    "md = HistGradientBoostingClassifier(\n",
    "        interaction_cst = \"no_interactions\",\n",
    "        categorical_features=\"from_dtype\",\n",
    "        max_iter=1000,\n",
    "        learning_rate=0.025,\n",
    "        max_leaf_nodes=100,\n",
    "        random_state=rng.integers(low=0, high=1000))\n",
    "md.fit(xtrain, ytrain)\n",
    "sammler.append(pd.Series(md.predict_proba(xtrain)[:,1], index=xtrain.index, name=\"GBT_wo\"))\n",
    "\n",
    "# GLM\n",
    "fml = \" ~ \" + \"+\".join(nm_var)\n",
    "md = GeneralizedLinearRegressor(\n",
    "            l1_ratio=0.0,\n",
    "            alpha=1e-6,\n",
    "            family=\"binomial\", \n",
    "            link=\"logit\",\n",
    "            fit_intercept=True,\n",
    "            drop_first=True,\n",
    "            formula = fml\n",
    "        )\n",
    "md.fit(xtrain, ytrain)\n",
    "sammler.append(pd.Series(md.predict(xtrain), index=xtrain.index, name=\"GLM\"))\n",
    "\n",
    "pred_tbl = pd.concat(sammler, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial aggregation transforms the iid dataset and creates unique(!) tuples respectively a MultiIndex, the according discrete probability measure and the functions as Series over the index.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:38.364521Z",
     "iopub.status.busy": "2024-07-29T20:11:38.364521Z",
     "iopub.status.idle": "2024-07-29T20:11:42.025498Z",
     "shell.execute_reply": "2024-07-29T20:11:42.025498Z",
     "shell.execute_reply.started": "2024-07-29T20:11:38.364521Z"
    }
   },
   "outputs": [],
   "source": [
    "# pre-aggregation rows are still iid, hence \"mean\" is OK\n",
    "agg_dict = {md: pd.NamedAgg(column=md, aggfunc=\"mean\") \n",
    "            for md in pred_tbl.columns}\n",
    "agg_dict[\"Actual_Recoveries\"] = pd.NamedAgg(column=\"Actual_Recoveries\", aggfunc=\"mean\")\n",
    "agg_dict[\"p\"] = pd.NamedAgg(column=\"Actual_Recoveries\", aggfunc=\"count\")\n",
    "\n",
    "tmp = pd.concat([Xbin, Y, pred_tbl], axis=1).set_index(nm_var, drop=True)\\\n",
    "    [[\"Actual_Recoveries\"] + pred_tbl.columns.to_list()]\n",
    "dfagg = tmp.groupby(nm_var, observed=True).agg(**agg_dict)\n",
    "p_master = dfagg[\"p\"] / dfagg[\"p\"].sum()\n",
    "p_master.name = \"master\"\n",
    "idx_master = p_master.index\n",
    "dfagg.drop(\"p\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions to be analysed are not only the three models from above but also the raw data itself, i.e. the \"Actual_Recoveries\". This is possible, because only observed inputs are used in the calculations of the statistics, and for observed inputs exist Actual_Recoveries. These observations can be handled in exactly the same way as function values on observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on probability level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis on probability level means, that the unmodified outputs of models are used for the calculation of the various statistics. These outputs are probabilities, hence the name. This is in contrast to analysis of the linear response, where function outputs are transformed by a link function. We will shortly see that the level of analysis does make a big difference, especially for interactions.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:42.027501Z",
     "iopub.status.busy": "2024-07-29T20:11:42.026501Z",
     "iopub.status.idle": "2024-07-29T20:11:42.029684Z",
     "shell.execute_reply": "2024-07-29T20:11:42.029684Z",
     "shell.execute_reply.started": "2024-07-29T20:11:42.027501Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_and_variance(fdf, p_master):\n",
    "    f_mean = fdf.multiply(p_master, axis=0).sum()\n",
    "    f_mean.name = \"mean\"\n",
    "    f_mean.index.name = \"f\"\n",
    "    ff = fdf - f_mean\n",
    "    V = (ff ** 2).multiply(p_master, axis=0).sum()\n",
    "    V.name = \"variance\"\n",
    "    V.index.name = \"f\"\n",
    "    return (f_mean, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:42.030688Z",
     "iopub.status.busy": "2024-07-29T20:11:42.030688Z",
     "iopub.status.idle": "2024-07-29T20:11:42.509000Z",
     "shell.execute_reply": "2024-07-29T20:11:42.509000Z",
     "shell.execute_reply.started": "2024-07-29T20:11:42.030688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8dc83\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8dc83_level0_col0\" class=\"col_heading level0 col0\" >mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >f</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8dc83_level0_row0\" class=\"row_heading level0 row0\" >GBT_with</th>\n",
       "      <td id=\"T_8dc83_row0_col0\" class=\"data row0 col0\" >0.014165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dc83_level0_row1\" class=\"row_heading level0 row1\" >GBT_wo</th>\n",
       "      <td id=\"T_8dc83_row1_col0\" class=\"data row1 col0\" >0.014149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dc83_level0_row2\" class=\"row_heading level0 row2\" >GLM</th>\n",
       "      <td id=\"T_8dc83_row2_col0\" class=\"data row2 col0\" >0.014146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dc83_level0_row3\" class=\"row_heading level0 row3\" >Actual_Recoveries</th>\n",
       "      <td id=\"T_8dc83_row3_col0\" class=\"data row3 col0\" >0.014146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6e791\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e791_level0_col0\" class=\"col_heading level0 col0\" >variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >f</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e791_level0_row0\" class=\"row_heading level0 row0\" >GBT_with</th>\n",
       "      <td id=\"T_6e791_row0_col0\" class=\"data row0 col0\" >0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e791_level0_row1\" class=\"row_heading level0 row1\" >GBT_wo</th>\n",
       "      <td id=\"T_6e791_row1_col0\" class=\"data row1 col0\" >0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e791_level0_row2\" class=\"row_heading level0 row2\" >GLM</th>\n",
       "      <td id=\"T_6e791_row2_col0\" class=\"data row2 col0\" >0.001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e791_level0_row3\" class=\"row_heading level0 row3\" >Actual_Recoveries</th>\n",
       "      <td id=\"T_6e791_row3_col0\" class=\"data row3 col0\" >0.012910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_mean, V = mean_and_variance(dfagg, p_master)\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = f_mean.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = V.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_()\n",
    "             + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The means are more or less equal, as is to be expected, since all the models are well calibrated. Further information on the calibration of the models' is contained in the notebook \"rep_marginal\".\n",
    "* The variance of Actual_Recoveries is almost 10 times larger than the variance of the models. This is because Actual_Recoveries are raw data, they contain residual error and consist of 0–1 observations instead of probabilities in $]0, 1[$. In contrast, the models are deterministic functions of the inputs, i.e. without residual error, and they produce never 0 or 1 values but something closer to the mean, which reduces the variance.\n",
    "* The models GLM and GBT_wo have about the same variance, which is much less than the variance of GBT_with. This is an indication of the greater flexibility of \"GBT_with\" to fit the data, but may be also an indication of overfitting.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First order Sobol Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order Sobol index of a function, is the variance of the conditional expectation with respect to one of the inputs. It is a very simple and intuitive notion of variable importance. A function which is nearly constant, will have a low index, while functions with a wide range and variation between categories will get larger ones. Compare the following results with the plots of the marginal functions in the notebook \"rep_marginal\". The first order Sobol indices are quantitative summaries of those graphs, and provide the foundation for the intuitive notion, that a variable matters, if it distinguishes well between categories.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:42.510005Z",
     "iopub.status.busy": "2024-07-29T20:11:42.509000Z",
     "iopub.status.idle": "2024-07-29T20:11:42.513507Z",
     "shell.execute_reply": "2024-07-29T20:11:42.513507Z",
     "shell.execute_reply.started": "2024-07-29T20:11:42.510005Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_order_sobol(fdf):\n",
    "    \n",
    "    sammler = []\n",
    "    for vnm in fdf.index.names:\n",
    "        # conditional probability\n",
    "        p_1 = p_master.groupby(level=vnm, observed=True).sum()\n",
    "        # conditional expectations\n",
    "        f_1 = fdf.multiply(p_master, axis=0).groupby(level=vnm, observed=True).sum()\n",
    "        # don't forget to divide by the marginal probability\n",
    "        f_1 = f_1.divide(p_1, axis=0)\n",
    "        V1 = ((f_1 ** 2).multiply(p_1, axis=0).sum() -\n",
    "             (f_1.multiply(p_1, axis=0).sum())**2)\n",
    "        sammler.append(V1)\n",
    "\n",
    "    V_1 = pd.concat(sammler, keys=fdf.index.names, names= [\"input\", \"f\"])\n",
    "    return V_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:42.514510Z",
     "iopub.status.busy": "2024-07-29T20:11:42.514510Z",
     "iopub.status.idle": "2024-07-29T20:11:44.321369Z",
     "shell.execute_reply": "2024-07-29T20:11:44.321369Z",
     "shell.execute_reply.started": "2024-07-29T20:11:42.514510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>f</th>\n",
       "      <th>Actual_Recoveries</th>\n",
       "      <th>GBT_with</th>\n",
       "      <th>GBT_wo</th>\n",
       "      <th>GLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Combined_SSA</th>\n",
       "      <td>4.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>38.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_Month</th>\n",
       "      <td>2.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>25.3</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccToAnyTransition</th>\n",
       "      <td>2.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <td>1.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attained_Age</th>\n",
       "      <td>0.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elimination_Period</th>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_at_Disability</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Integration_with_STD</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benefit_Max_Limit_Proxy</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross_Indexed_Benefit_Amount</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxability_of_Benefits</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental_and_Nervous_Period</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indexed_Monthly_Salary</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case_Size</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_N_Limit_Transition</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Replacement_Ratio</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residence_State</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLA_Indicator</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_of_Study</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "f                             Actual_Recoveries  GBT_with  GBT_wo   GLM\n",
       "input                                                                  \n",
       "Combined_SSA                                4.1      32.0    42.0  38.2\n",
       "Duration_Month                              2.6      20.8    25.3  24.4\n",
       "OwnOccToAnyTransition                       2.1      15.8    20.7  19.2\n",
       "Diagnosis_Category                          1.8      13.1    16.4  16.7\n",
       "Attained_Age                                0.8       6.0     7.8   7.3\n",
       "Elimination_Period                          0.3       2.4     3.1   3.2\n",
       "Age_at_Disability                           0.2       1.5     1.7   1.9\n",
       "Integration_with_STD                        0.1       0.9     1.1   1.2\n",
       "Benefit_Max_Limit_Proxy                     0.1       1.1     1.6   1.2\n",
       "Industry                                    0.1       1.0     1.2   1.1\n",
       "Gross_Indexed_Benefit_Amount                0.1       0.9     1.0   1.1\n",
       "Taxability_of_Benefits                      0.1       0.8     1.1   0.9\n",
       "Mental_and_Nervous_Period                   0.1       0.7     0.9   0.9\n",
       "Indexed_Monthly_Salary                      0.1       0.7     0.8   0.8\n",
       "Case_Size                                   0.1       0.6     0.7   0.8\n",
       "M_N_Limit_Transition                        0.1       0.5     0.5   0.6\n",
       "Replacement_Ratio                           0.1       0.5     0.6   0.6\n",
       "Gender                                      0.0       0.2     0.2   0.3\n",
       "Residence_State                             0.0       0.2     0.2   0.2\n",
       "COLA_Indicator                              0.0       0.1     0.1   0.1\n",
       "Month_of_Study                              0.0       0.0     0.0   0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1 = first_order_sobol(dfagg) / V\n",
    "tmp = S_1.unstack()\n",
    "round( tmp.sort_values(by=\"Actual_Recoveries\", ascending=False) *100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above shows the relative variance of each main effects function to the total variance in percent. The values can be interpreted as the percentage of variance explained by the respective main effects.\n",
    "\n",
    "Observations: \n",
    "* All functions agree on the ranking of the inputs.\n",
    "* Only a few inputs have large Sobol indices. The inputs deemed important and their ranking is consistent with the other importance measures, such as drop1 or permutation feature importance. See the respective notebooks `exp_drop1_*` and `exp_pfi` for more details on those. \n",
    "* The index values for Actual Recoveries are much lower. Recall, that the Sobol index is the amount of variance explained by the main effect function. But Actual_Recoveries has a much larger total variance, i.e. the denominator of the Sobol index is much larger, hence the index is smaller. This makes a direct comparison between functions with very different total variances difficult.  \n",
    "* In comparison to the models without interactions, the values for GBT_with are lower. We will see that the reason are interactions.\n",
    "* The values will, in general, never add up to 100%. There are two reasons for this. First, the contributions of the interactions are missing, this is only about the main effects. And, second, the inputs are not stochastic independent, hence the main effects functions will be correlated, which means their variances will not add up to the total variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total interaction index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total interaction index is based on a split of each of the functions into two uniquely defined components. An additive part, which is a linear combination of all available main effects functions, and its complement, i.e. \n",
    "$$ f = f_\\text{add} + f_\\text{inter}.$$\n",
    "As in FANOVA and described in \"edu_Hcorr\" the decomposition of $f$ is derived from an orthogonal decomposition of the function space into two components. In fact, $f_\\text{add}$ is defined as the best least squares approximation of a sum of main effects to $f$ and $f_\\text{inter}$ as the residual. By construction, the two components are uncorrelated, hence they provide an additive split of the total variance of $f$:\n",
    "$$ \\mathbb{V}[f] = \\mathbb{V}[f_\\text{add}] + \\mathbb{V}[f_\\text{inter}].$$\n",
    "Below we show the relative amounts of $\\frac{\\mathbb{V}[f_\\text{add}]}{\\mathbb{V}[f]}$ and $\\frac{\\mathbb{V}[f_\\text{inter}]}{\\mathbb{V}[f]}$ in percent for each of the three models and the raw data, i.e. the `Actual_Recoveries`.\n",
    "\n",
    "The notebook \"edu_Hcorr\" contains more background and details on theory and implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, a basis for the space of additive functions is constructed. Here, the \"drop first\" approach is used, where one column of the matrix representing the basis is removed. See also the discussion and examples in Section \"Definition of $\\mathscr{V}_1$\" of the accompanying notebook `edu_Hcorr`. The linear independence of this basis, is verified using `matrix_rank` from `np.linalg`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:44.329713Z",
     "iopub.status.busy": "2024-07-29T20:11:44.329713Z",
     "iopub.status.idle": "2024-07-29T20:11:46.794074Z",
     "shell.execute_reply": "2024-07-29T20:11:46.794074Z",
     "shell.execute_reply.started": "2024-07-29T20:11:44.329713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function space V_add has dimension: 228.\n"
     ]
    }
   ],
   "source": [
    "sammler = []\n",
    "# build main effects basis\n",
    "for vnm in nm_var:\n",
    "    ct = idx_master.levels[idx_master.names.index(vnm)]\n",
    "    # df is \"drop1\" due to [:,1:]\n",
    "    df = pd.DataFrame(np.identity(len(ct))[:,1:], index=ct.astype(str))\n",
    "    # broadcast to full index\n",
    "    sammler.append(df.reindex(index=idx_master, level=vnm))\n",
    "\n",
    "tmp = pd.concat([pd.Series(1, index=idx_master)] + sammler, \n",
    "                keys=[\"const\"] + nm_var, axis=1)\n",
    "# normalise coordinates\n",
    "basmat_main = tmp.multiply(np.sqrt(p_master), axis=0).to_numpy()\n",
    "dim_bas = basmat_main.shape[1]\n",
    "assert(dim_bas==np.linalg.matrix_rank(basmat_main))\n",
    "print(f\"The function space V_add has dimension: {dim_bas}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the functions' coordinates are transformed to normalized coordinates, such that the standard linear algebra routines can be applied. The scipy function `lstsq` does really all the computational work, and $f_\\text{inter}$ is the residual of the least squares solution. One could retrieve the actual components of the vectors for further analysis, (they are `basmat_main @ x` and `dfagg - basmat_main @ x`) but this is not done in this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:46.795079Z",
     "iopub.status.busy": "2024-07-29T20:11:46.795079Z",
     "iopub.status.idle": "2024-07-29T20:11:52.710129Z",
     "shell.execute_reply": "2024-07-29T20:11:52.710129Z",
     "shell.execute_reply.started": "2024-07-29T20:11:46.795079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_add</th>\n",
       "      <th>V_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBT_with</th>\n",
       "      <td>59.4</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>75.1</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>72.5</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Recoveries</th>\n",
       "      <td>7.8</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   V_add  V_inter\n",
       "GBT_with            59.4     40.6\n",
       "GBT_wo              75.1     24.9\n",
       "GLM                 72.5     27.5\n",
       "Actual_Recoveries    7.8     92.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract functions and normalize coordinates\n",
    "f_cb = dfagg.multiply(np.sqrt(p_master), axis=0).to_numpy()\n",
    "x, resi, rk, sval = linalg.lstsq(basmat_main, f_cb)\n",
    "# check if something went wrong\n",
    "assert(dim_bas == rk)\n",
    "V_inter_total = pd.Series(resi, index=dfagg.columns)\n",
    "V_add_total = V - V_inter_total\n",
    "round(pd.concat([V_add_total / V, V_inter_total / V], axis=1, keys=[\"V_add\", \"V_inter\"]) * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown above is per function the relative amounts of variance as percentage, i.e. the amount of total variance explained by the interaction component.  \n",
    "* The low value for the additive component of Actual Recoveries does not mean that the raw data is almost exclusively determined by interactions. Instead, this is again an effect of the high residual variance, which is fully assigned to the interaction part.\n",
    "* The split for the models is a better indicator of the model structure, since this split is not distorted by residual variance, as the models are deterministic.\n",
    "* The interaction values for the two models *without* interaction might seem surprising. They are smaller than those for the model with interaction, but they are somewhat large and definitely not zero! The reason is the link function. See the next chapter on analysis on logit level.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on logit level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with probabilities as a target for the analysis of interactions, stems from the fact that GLMs are indeed linear functions of features of the inputs, but those are transformed by a link function. In this notebook, the logit is used as a link function. This link function is not only applied for GLMs, but also for the GBT models. To quote from the Scikit-learn documentation of `HistGradientBoostingClassifier`:\n",
    "> Internally, the model fits one tree per boosting iteration and uses the logistic sigmoid function (expit) as inverse link function to compute the predicted positive class probability.\n",
    "\n",
    "Analysis, which takes place before the transformation by the link (i.e. logit) function, is called analysis on logit level. Analysis after the link function is applied, as it was done in the prior section, is called analysis on probability level. To appreciate the importance of this for the understanding of interactions, note that the recovery probability $\\pi,$ is linked to the linear predictor $X\\beta$ of a GLM by the logit, i.e.\n",
    "$$ \\text{logit}(\\pi(\\beta)) = X\\beta $$\n",
    "and\n",
    "$$ \\pi(\\beta)= \\frac{\\exp X\\beta}{1 + \\exp X\\beta}.$$\n",
    "But this means that the model will have interactions on the probability level, even if it is additive on the logit level. For this reason, interaction analysis should be performed on the logit level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-one entries are not defined for the logit transformation. Accordingly, analysis of the raw data is not possible on the linear level and \"Actual_Recoveries\" have to be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:52.710129Z",
     "iopub.status.busy": "2024-07-29T20:11:52.710129Z",
     "iopub.status.idle": "2024-07-29T20:11:52.749367Z",
     "shell.execute_reply": "2024-07-29T20:11:52.749367Z",
     "shell.execute_reply.started": "2024-07-29T20:11:52.710129Z"
    }
   },
   "outputs": [],
   "source": [
    "df_logit = np.log(dfagg[pred_tbl.columns] / (1 - dfagg[pred_tbl.columns]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:52.750371Z",
     "iopub.status.busy": "2024-07-29T20:11:52.750371Z",
     "iopub.status.idle": "2024-07-29T20:11:52.870256Z",
     "shell.execute_reply": "2024-07-29T20:11:52.870256Z",
     "shell.execute_reply.started": "2024-07-29T20:11:52.750371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4149c\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4149c_level0_col0\" class=\"col_heading level0 col0\" >mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >f</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4149c_level0_row0\" class=\"row_heading level0 row0\" >GBT_with</th>\n",
       "      <td id=\"T_4149c_row0_col0\" class=\"data row0 col0\" >-5.668123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4149c_level0_row1\" class=\"row_heading level0 row1\" >GBT_wo</th>\n",
       "      <td id=\"T_4149c_row1_col0\" class=\"data row1 col0\" >-5.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4149c_level0_row2\" class=\"row_heading level0 row2\" >GLM</th>\n",
       "      <td id=\"T_4149c_row2_col0\" class=\"data row2 col0\" >-5.701168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_64fac\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_64fac_level0_col0\" class=\"col_heading level0 col0\" >variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >f</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_64fac_level0_row0\" class=\"row_heading level0 row0\" >GBT_with</th>\n",
       "      <td id=\"T_64fac_row0_col0\" class=\"data row0 col0\" >2.153020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64fac_level0_row1\" class=\"row_heading level0 row1\" >GBT_wo</th>\n",
       "      <td id=\"T_64fac_row1_col0\" class=\"data row1 col0\" >2.208370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64fac_level0_row2\" class=\"row_heading level0 row2\" >GLM</th>\n",
       "      <td id=\"T_64fac_row2_col0\" class=\"data row2 col0\" >2.558656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_logit_mean, V_logit = mean_and_variance(df_logit, p_master)\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = f_logit_mean.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = V_logit.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_()\n",
    "             + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First order Sobol Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:52.871260Z",
     "iopub.status.busy": "2024-07-29T20:11:52.870256Z",
     "iopub.status.idle": "2024-07-29T20:11:54.567110Z",
     "shell.execute_reply": "2024-07-29T20:11:54.567110Z",
     "shell.execute_reply.started": "2024-07-29T20:11:52.871260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>f</th>\n",
       "      <th>GBT_with</th>\n",
       "      <th>GBT_wo</th>\n",
       "      <th>GLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duration_Month</th>\n",
       "      <td>44.4</td>\n",
       "      <td>57.7</td>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined_SSA</th>\n",
       "      <td>44.2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>46.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccToAnyTransition</th>\n",
       "      <td>32.4</td>\n",
       "      <td>39.8</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attained_Age</th>\n",
       "      <td>16.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benefit_Max_Limit_Proxy</th>\n",
       "      <td>5.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Integration_with_STD</th>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elimination_Period</th>\n",
       "      <td>2.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_at_Disability</th>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case_Size</th>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mental_and_Nervous_Period</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_N_Limit_Transition</th>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross_Indexed_Benefit_Amount</th>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Replacement_Ratio</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indexed_Monthly_Salary</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxability_of_Benefits</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residence_State</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLA_Indicator</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_of_Study</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "S_1_logit = first_order_sobol(df_logit) / V_logit\n",
    "tmp = S_1_logit.unstack()\n",
    "display_html(round( tmp.sort_values(by=\"GBT_wo\", ascending=False) *100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* On logit level the inputs have the same overall importance they had on probability level.\n",
    "* But, in comparison to the probability level, indices are larger, i.e. main effects are more important.\n",
    "* Clear difference between the model with interaction and the two models without interaction. The models without interaction show substantially larger main effects than the model with interaction.\n",
    "* Sum of indices is much larger than 100%, indication of positive correlations between the main effects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T12:57:27.190410Z",
     "iopub.status.busy": "2024-07-27T12:57:27.174785Z",
     "iopub.status.idle": "2024-07-27T12:57:27.199221Z",
     "shell.execute_reply": "2024-07-27T12:57:27.199221Z",
     "shell.execute_reply.started": "2024-07-27T12:57:27.190410Z"
    }
   },
   "source": [
    "## Total interaction index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interaction index is calculated in the same way as above. In particular the basis is identical. The only difference are the transformed functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:11:54.568115Z",
     "iopub.status.busy": "2024-07-29T20:11:54.568115Z",
     "iopub.status.idle": "2024-07-29T20:12:00.521616Z",
     "shell.execute_reply": "2024-07-29T20:12:00.521616Z",
     "shell.execute_reply.started": "2024-07-29T20:11:54.568115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_add</th>\n",
       "      <th>V_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBT_with</th>\n",
       "      <td>86.9</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          V_add  V_inter\n",
       "GBT_with   86.9     13.1\n",
       "GBT_wo    100.0      0.0\n",
       "GLM       100.0      0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract functions and normalise coordinates\n",
    "f_cb = df_logit.multiply(np.sqrt(p_master), axis=0).to_numpy()\n",
    "x, resi, rk, sval = linalg.lstsq(basmat_main, f_cb)\n",
    "# check if something went wrong\n",
    "assert(dim_bas == rk)\n",
    "V_logit_inter_total = pd.Series(resi, index=df_logit.columns)\n",
    "V_logit_add_total = V_logit - V_logit_inter_total\n",
    "round(pd.concat([V_logit_add_total / V_logit, V_logit_inter_total / V_logit], \n",
    "                axis=1, keys=[\"V_add\", \"V_inter\"]) * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the split is as expected. The variance of models without interaction is fully explained by additive combinations of the main effects functions, while for the GBT with interactions, a substantial amount of variance remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second order indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total interaction index is based on the split between two orthogonal spaces. The space of additive functions and its orthogonal complement. Total interaction can tell if and how much interaction is present. It does not provide information on what inputs are interacting. To shed light on this question, further refinement is required. This section provides exactly this refinement. Instead of starting with the whole function space and splitting this into two components, we start with a bivariate function spaces, i.e. a space of conditional expectation with respect to two inputs, and split this into main effects and interaction. The implementation in the code block below works basically in the same way as the code for the total interaction index. The only differences consist in the  loop over all pairs, and the calculation of the bivariate conditional expectation for each pair.\n",
    "\n",
    "On first sight, it may seem surprising that the same basis (`basmat_main`) is used for the bivariate functions as was used for the multivariate functions. But this is necessary due to the stochastic dependence between the inputs. In this case, the best additive approximation to $\\mathbb{E}[f\\vert A,B]$ will not only involve functions with inputs $A$ and $B$ but also functions of correlated inputs. Again, this can be analysed in detail because all functions in the decomposition can be explicitly computed. But this is not done here, and left to the interested reader.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only selected pairs are shown, since there are in total about 200 pairs, and the analysis of first order and total indices shows that only a few of them have any relevance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:12:00.522621Z",
     "iopub.status.busy": "2024-07-29T20:12:00.522621Z",
     "iopub.status.idle": "2024-07-29T20:14:00.391988Z",
     "shell.execute_reply": "2024-07-29T20:14:00.391988Z",
     "shell.execute_reply.started": "2024-07-29T20:12:00.522621Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculation for each pair of inputs\n",
    "pairs = list(itertools.combinations([\"Duration_Month\", \"Combined_SSA\", \"OwnOccToAnyTransition\", \"Attained_Age\", \"Diagnosis_Category\", \"Benefit_Max_Limit_Proxy\"],2))\n",
    "# the use of frames instead of indices is required for unknown Pandas reasons\n",
    "# .reindex does not accept more than one level so that we need .join \n",
    "df_master = idx_master.to_frame().reset_index(drop=True)\n",
    "\n",
    "sammler = []\n",
    "for nm_pair in pairs:\n",
    "    # determine conditional distribution of pair\n",
    "    p_2 = p_master.groupby(level=nm_pair, observed=True).sum()\n",
    "    # Conditional expectation on idx_2\n",
    "    f_2 = df_logit.multiply(p_master, axis=0).groupby(level=nm_pair, observed=True).sum()\n",
    "    f_2 = f_2.divide(p_2, axis=0)\n",
    "    # find variance\n",
    "    f_2_var = ((f_2 ** 2).multiply(p_2, axis=0).sum() \n",
    "               - (f_2.multiply(p_2, axis=0).sum())**2)\n",
    "    # reindex/embed\n",
    "    f_2_emb = df_master.join(f_2, on=nm_pair, how=\"left\").set_index(nm_var)\n",
    "\n",
    "    # to find residual f_2_emb has to be transformed to normalised coordinates \n",
    "    f_cb = f_2_emb.multiply(np.sqrt(p_master), axis=0).to_numpy()\n",
    "    x, resi, rk, sval = linalg.lstsq(basmat_main, f_cb)\n",
    "    sammler.append(pd.concat([f_2_var, pd.Series(resi, index=df_logit.columns)],\n",
    "                    axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:14:00.392992Z",
     "iopub.status.busy": "2024-07-29T20:14:00.392992Z",
     "iopub.status.idle": "2024-07-29T20:14:00.404464Z",
     "shell.execute_reply": "2024-07-29T20:14:00.404464Z",
     "shell.execute_reply.started": "2024-07-29T20:14:00.392992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>V_2</th>\n",
       "      <th>V_inter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>f</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">Duration_Month</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Combined_SSA</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>81.7</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>85.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">OwnOccToAnyTransition</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>61.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>57.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Attained_Age</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>52.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>61.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>61.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diagnosis_Category</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>49.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>59.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Benefit_Max_Limit_Proxy</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>45.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>58.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>55.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Combined_SSA</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">OwnOccToAnyTransition</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>68.3</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>77.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>70.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Attained_Age</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>52.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>57.2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>54.1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diagnosis_Category</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>48.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>57.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>51.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Benefit_Max_Limit_Proxy</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>47.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>56.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>50.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">OwnOccToAnyTransition</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Attained_Age</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>42.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>44.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diagnosis_Category</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>37.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>45.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>42.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Benefit_Max_Limit_Proxy</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>34.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>41.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>38.6</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Attained_Age</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diagnosis_Category</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>23.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>19.1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>22.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Benefit_Max_Limit_Proxy</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>21.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>28.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diagnosis_Category</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Benefit_Max_Limit_Proxy</th>\n",
       "      <th>GBT_with</th>\n",
       "      <td>12.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT_wo</th>\n",
       "      <td>14.6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM</th>\n",
       "      <td>14.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         V_2  V_inter\n",
       "A                     B                       f                      \n",
       "Duration_Month        Combined_SSA            GBT_with  81.7      6.2\n",
       "                                              GBT_wo    91.0      0.1\n",
       "                                              GLM       85.1      0.1\n",
       "                      OwnOccToAnyTransition   GBT_with  47.0      0.2\n",
       "                                              GBT_wo    61.2      0.0\n",
       "                                              GLM       57.9      0.0\n",
       "                      Attained_Age            GBT_with  52.4      1.0\n",
       "                                              GBT_wo    61.4      0.9\n",
       "                                              GLM       61.4      1.0\n",
       "                      Diagnosis_Category      GBT_with  49.7      1.6\n",
       "                                              GBT_wo    62.0      0.4\n",
       "                                              GLM       59.1      0.4\n",
       "                      Benefit_Max_Limit_Proxy GBT_with  45.3      0.1\n",
       "                                              GBT_wo    58.5      0.1\n",
       "                                              GLM       55.5      0.1\n",
       "Combined_SSA          OwnOccToAnyTransition   GBT_with  68.3      2.8\n",
       "                                              GBT_wo    77.8      0.4\n",
       "                                              GLM       70.5      0.4\n",
       "                      Attained_Age            GBT_with  52.1      0.9\n",
       "                                              GBT_wo    57.2      0.7\n",
       "                                              GLM       54.1      0.8\n",
       "                      Diagnosis_Category      GBT_with  48.3      0.8\n",
       "                                              GBT_wo    57.5      0.3\n",
       "                                              GLM       51.3      0.3\n",
       "                      Benefit_Max_Limit_Proxy GBT_with  47.4      0.9\n",
       "                                              GBT_wo    56.6      0.8\n",
       "                                              GLM       50.7      0.8\n",
       "OwnOccToAnyTransition Attained_Age            GBT_with  42.5      0.3\n",
       "                                              GBT_wo    44.9      0.3\n",
       "                                              GLM       45.0      0.5\n",
       "                      Diagnosis_Category      GBT_with  37.9      0.9\n",
       "                                              GBT_wo    45.4      0.3\n",
       "                                              GLM       42.1      0.3\n",
       "                      Benefit_Max_Limit_Proxy GBT_with  34.3      0.6\n",
       "                                              GBT_wo    41.8      0.8\n",
       "                                              GLM       38.6      0.7\n",
       "Attained_Age          Diagnosis_Category      GBT_with  23.3      0.6\n",
       "                                              GBT_wo    19.1      0.7\n",
       "                                              GLM       22.6      0.5\n",
       "                      Benefit_Max_Limit_Proxy GBT_with  26.0      0.2\n",
       "                                              GBT_wo    21.6      0.2\n",
       "                                              GLM       28.7      0.2\n",
       "Diagnosis_Category    Benefit_Max_Limit_Proxy GBT_with  12.9      0.3\n",
       "                                              GBT_wo    14.6      0.3\n",
       "                                              GLM       14.9      0.3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_inter_pairs = pd.concat(sammler, keys=pairs, names=[\"A\", \"B\", \"f\"])\n",
    "V_inter_pairs.columns = [\"V_2\", \"V_inter\"]\n",
    "round(V_inter_pairs.divide(V_logit, axis=0, level=\"f\") * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Only GBT_with and only three pairs (Duration_Month, Combined_SSA), (Combined_SSA, OwnOccToAnyTransition) and (Duration_Month, Diagnosis_Category) have interaction values larger than 1.5%.\n",
    "* For all three models, most interaction values are small but non-zero.\n",
    "* GBT_with values are larger than the values without interaction.\n",
    "\n",
    "The most likely reason for the small but non-zero `V_inter` values, especially for the non-interaction models, are contributions from correlated bivariate functions. Since all these functions are explicitly available, further analysis could be performed, but again this is left to the interested reader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T20:14:00.405592Z",
     "iopub.status.busy": "2024-07-29T20:14:00.404972Z",
     "iopub.status.idle": "2024-07-29T20:14:00.408034Z",
     "shell.execute_reply": "2024-07-29T20:14:00.408034Z",
     "shell.execute_reply.started": "2024-07-29T20:14:00.405592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took: 6.0min.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time it took: {np.ceil((time.time() - tic)/60)}min.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have demonstrated how to split the models into two orthogonal components, one additive and one interaction component. We were able to clearly distinguish between the models with and without interaction and could measure the amount of interaction by allocated variance. All without the use of impossible data and within convenient run-time limits.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLTD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
