{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Simon-Style -->\n",
    "<p style=\"font-size:19px; text-align:left; margin-top:    15px;\"><i>German Association of Actuaries (DAV) — Working Group \"Explainable Artificial Intelligence\"</i></p>\n",
    "<p style=\"font-size:25px; text-align:left; margin-bottom: 15px\"><b>Use Case SOA GLTD Experience Study:<br>\n",
    "PDPs and impossible data for categorical variables\n",
    "</b></p>\n",
    "<p style=\"font-size:19px; text-align:left; margin-bottom: 15px; margin-bottom: 15px\">Guido Grützner (<a href=\"mailto:guido.gruetzner@quantakt.com\">guido.gruetzner@quantakt.com</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\expect}[1]{\\mathbb{E}{\\left[#1\\right]}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook discusses Partial Dependence Plots (PDP) with dependent inputs for the special case of categorical data. We use a simple case study with real actuarial data (GLTD use case) to demonstrate issues which will arise (or have arisen) in many practical applications. In particular, we discuss:\n",
    "* What is meant by \"impossible data\" and how it is encountered in practice.\n",
    "* How PDPs in the way they are typically defined and implemented in standard libraries such as Scikit-learn, rely on impossible data.\n",
    "* Demonstrate in the example why and how impossible data, and hence, the use of PDPs is misleading.\n",
    "* Propose a simple and straightforward alternative to PDPs for categorical data.\n",
    "\n",
    "A note on terminology: This notebook does not show any plots. We only discuss the *functions* which will ultimately provide the data for actual plots. It would be natural to call them partial dependence functions, but this abbreviates to *pdf*, which may be confusing. So we slightly generalize terminology and abbreviate those functions by PDP as well. We use the general term *marginal functions* for functions of a single input, which are somehow derived from a function with more than a single input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of PDP and impossible data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, and because generalization is straightforward, we discuss only the case where our function or model of interest has two categorical variables as input:\n",
    "$$ f:\\mathcal{X}_A\\times\\mathcal{X}_B\\rightarrow\\mathbb{R}\\quad, \\quad (A,B)\\mapsto f(A,B)$$\n",
    "where $\\mathcal{X}_A$ respectively $\\mathcal{X}_B$ are the possible levels of each categorical variable.\n",
    "\n",
    "In this case, there are two PDPs, one for each input. The PDP depending only on $A$ is called $f_A$, the other, depending only on $B$, is called $f_B$. The standard definition of PDP is based on the empirical measures, i.e. calculated using an iid sample of size $N$ $(a_k,b_k)\\in\\mathcal{X}$ for $k=1,\\ldots, N$ \n",
    "from the domain of definition of $f$ as follows:\n",
    "\\begin{align*}\n",
    "\\text{PDP: } \\quad &  f_A(a_j) = \\frac 1 N \\sum_{k=1}^N f(a_j,b_k) \\\\\n",
    "    & f_B(b_k) = \\frac 1 N \\sum_{j=1}^N f(a_j,b_k).\n",
    "\\end{align*} \n",
    "This expression is just a special case of the more general principle of \"integrating out\" or \"marginalizing\" a variable. Appreciating this, the PDP can be understood and written as an expectation:\n",
    "$$ f_A(a) = \\mathbb{E}_B[f(a,B)]$$\n",
    "where $\\mathbb{E}_B$ is the expectation with respect to the marginal distribution of $B$ and $a$ one of the levels from $\\mathcal{X}_A$ of the first input. \n",
    "Another function, derived from $f$, which also depends only on a single argument, is the conditional expectation\n",
    "$$ \\tilde{f}_A(a) = \\expect{f(A,B) \\vert A=a}.$$ \n",
    "The difference between these expressions is, that the first one uses only the marginal distribution, but the second one the joint distribution. If $A$ and $B$ are independent, then both definitions agree, i.e. in that case $f=\\tilde{f}.$ But in general, if the margins are not independent, the functions $f$ and $\\tilde f$ will differ. This notebook does nothing more, than exploring this difference in a concrete case study.\n",
    "\n",
    "Notice that the first definition of PDP, using the sum over the $b_k$, implicitly assumes independence. This is because the $\\frac 1 N$ and the sum without weights, is only a valid average or expectation, if each term in the sum has equal probability. But the terms of the sum include combinations $(a_j, b_k)$ with $j\\neq k$ which are different from the observed combinations $(a_k, b_k).$ These \"new\" combinations may not have identical probabilities of occurrence, or may not even occur at all in the data for dependent inputs. This practice, treating those expressions as iid even though they may have different probabilities or may even not occur at all in the data, creates the \"impossible data problem\".    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook studies a particularly simple case, categorical inputs, where all probabilities and expectations, conditional or not, can be computed by elementary arithmetic. In our example, the two inputs have three levels each, which means there are in total 3-by-3 or nine possible combinations. Recall that the probabilities of these combinations, which yield the joint probability distribution, can be found by normalizing a crosstabulation of the data sample. This means nothing else than counting how often each combination occurs in the sample (crosstabulation) and then dividing by the total sample size (normalizing). The same is done for the three combinations making up each of the two the marginal distributions. An important advantage of discrete distributions over continuous ones is the possibility to calculate conditional probabilities and conditional expectations directly from a sample. Conditional probabilities, in terms of the 3-by-3 table of our example, are just the probabilities in a row or column, which are turned into a proper probability distribution in their own right, by normalizing their sum to one, i.e. by dividing each probability by their row or column sum, which is the respective marginal probability. You can check and verify these (simple) calculations in detail in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T16:34:31.079244Z",
     "iopub.status.busy": "2024-11-13T16:34:31.079244Z",
     "iopub.status.idle": "2024-11-13T16:34:32.828094Z",
     "shell.execute_reply": "2024-11-13T16:34:32.828094Z",
     "shell.execute_reply.started": "2024-11-13T16:34:31.079244Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from IPython.display import display, display_html\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of use case and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this notebook, no knowledge of the source of the data or its intended use is required. We just provide limited background for completeness.\n",
    "\n",
    "The dataset, which is provided with this notebook, is an extract of a much larger dataset by the Society of Actuaries. The original data can be found at the Society of Actuaries' website under [\"2019 Group Long-Term Disability Experience Study Preliminary Report\"](https://www.soa.org/resources/experience-studies/2019/group-ltd-experience-study/). The goal of the study is to predict recovery probabilities of Group Long Term Disability claims for the US market for further use in pricing and reserving.\n",
    "\n",
    " For our purposes, only the structure of the data is relevant. It consists of observations (rows) of two categorical columns, which are the inputs, and an according numeric column which takes values 0 and 1, which is the response. A value of 1 means a recovery has occurred, a value of zero means no recovery. The goal is to predict the probability of recovery, given the inputs. Hence, it is a standard Bernoulli regression. We are not interested in the model per se or its predictive quality, since in this simplified setting, it is more or less trivial anyway. We just use this simplified data and the model to demonstrate the issues with PDPs.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the path to the input file in the following block, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T16:34:32.828094Z",
     "iopub.status.busy": "2024-11-13T16:34:32.828094Z",
     "iopub.status.idle": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply": "2024-11-13T16:34:33.106946Z",
     "shell.execute_reply.started": "2024-11-13T16:34:32.828094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1910337 observations in the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Updated_SSA     category\n",
       "Original_SSA    category\n",
       "Recovery           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"./GLTD_SSA_extract.feather\")\n",
    "print(f\"There are {len(data)} observations in the data.\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.107026Z",
     "iopub.status.idle": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.107026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable `Original_SSA` has the categories ['N', 'U', 'Y']\n",
      "The variable `Updated_SSA` has the categories ['No', 'Unknown', 'Yes']\n",
      "The variable `Revovery` takes the values [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The variable `Original_SSA` has the categories {list(data[\"Original_SSA\"].cat.categories)}\")\n",
    "print(f\"The variable `Updated_SSA` has the categories {list(data[\"Updated_SSA\"].cat.categories)}\")\n",
    "print(f\"The variable `Revovery` takes the values {list(data[\"Recovery\"].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, the observations are aggregated as a table. Normalizing the table entries gives the joint empirical probability distribution of the input variables in the sample. Doing the same for the margins gives the marginal empirical probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.107026Z",
     "iopub.status.idle": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.107026Z"
    }
   },
   "outputs": [],
   "source": [
    "nm_0 = \"Original_SSA\"\n",
    "nm_1 = \"Updated_SSA\"\n",
    "allcategories = [data[cat].cat.categories for cat in [nm_0, nm_1]]\n",
    "\n",
    "# crosstab does all the work of binning the dataframe, note we normalize and\n",
    "# calculate the margins as well in one go. \n",
    "tmp = pd.crosstab(data[nm_0], data[nm_1], \n",
    "                      normalize=True, margins=True)\n",
    "# extract marginal probabilities\n",
    "p_0 = tmp.loc[allcategories[0], \"All\"]\n",
    "p_0.index.name = nm_0\n",
    "p_0.name = \"margin\"\n",
    "p_1 = tmp.loc[\"All\", allcategories[1]]\n",
    "p_1.index.name = nm_1\n",
    "p_1.name = \"margin\"\n",
    "# p_margin contains two Series over different indices, hence not a DataFrame\n",
    "p_margin = {nm_0: p_0, nm_1: p_1}\n",
    "\n",
    "# extract the joint probability\n",
    "tmp.drop([\"All\"], axis=1,inplace=True)\n",
    "tmp.drop([\"All\"], axis=0,inplace=True)\n",
    "p_observed = tmp.stack()\n",
    "p_observed.name = \"joint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table of joint probabilities and the two marginal probability tables are displayed below. The \"impossible\" combinations, i.e. those which have not been observed, have probability zero and are coloured <span style=\"color:red\">red</span>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.107026Z",
     "iopub.status.idle": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.107026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2f4ea_row0_col1, #T_2f4ea_row0_col2, #T_2f4ea_row1_col0, #T_2f4ea_row1_col2 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2f4ea\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Updated_SSA</th>\n",
       "      <th id=\"T_2f4ea_level0_col0\" class=\"col_heading level0 col0\" >No</th>\n",
       "      <th id=\"T_2f4ea_level0_col1\" class=\"col_heading level0 col1\" >Unknown</th>\n",
       "      <th id=\"T_2f4ea_level0_col2\" class=\"col_heading level0 col2\" >Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Original_SSA</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2f4ea_level0_row0\" class=\"row_heading level0 row0\" >N</th>\n",
       "      <td id=\"T_2f4ea_row0_col0\" class=\"data row0 col0\" >0.117028</td>\n",
       "      <td id=\"T_2f4ea_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_2f4ea_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f4ea_level0_row1\" class=\"row_heading level0 row1\" >U</th>\n",
       "      <td id=\"T_2f4ea_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_2f4ea_row1_col1\" class=\"data row1 col1\" >0.066749</td>\n",
       "      <td id=\"T_2f4ea_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f4ea_level0_row2\" class=\"row_heading level0 row2\" >Y</th>\n",
       "      <td id=\"T_2f4ea_row2_col0\" class=\"data row2 col0\" >0.129784</td>\n",
       "      <td id=\"T_2f4ea_row2_col1\" class=\"data row2 col1\" >0.015232</td>\n",
       "      <td id=\"T_2f4ea_row2_col2\" class=\"data row2 col2\" >0.671206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a24d4\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a24d4_level0_col0\" class=\"col_heading level0 col0\" >margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Original_SSA</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a24d4_level0_row0\" class=\"row_heading level0 row0\" >N</th>\n",
       "      <td id=\"T_a24d4_row0_col0\" class=\"data row0 col0\" >0.117028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a24d4_level0_row1\" class=\"row_heading level0 row1\" >U</th>\n",
       "      <td id=\"T_a24d4_row1_col0\" class=\"data row1 col0\" >0.066749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a24d4_level0_row2\" class=\"row_heading level0 row2\" >Y</th>\n",
       "      <td id=\"T_a24d4_row2_col0\" class=\"data row2 col0\" >0.816223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c060f\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c060f_level0_col0\" class=\"col_heading level0 col0\" >margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Updated_SSA</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c060f_level0_row0\" class=\"row_heading level0 row0\" >No</th>\n",
       "      <td id=\"T_c060f_row0_col0\" class=\"data row0 col0\" >0.246812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c060f_level0_row1\" class=\"row_heading level0 row1\" >Unknown</th>\n",
       "      <td id=\"T_c060f_row1_col0\" class=\"data row1 col0\" >0.081982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c060f_level0_row2\" class=\"row_heading level0 row2\" >Yes</th>\n",
       "      <td id=\"T_c060f_row2_col0\" class=\"data row2 col0\" >0.671206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the conditional formatting\n",
    "styled_df = p_observed.unstack().style.apply(\n",
    "    lambda row: [None if el>0 else \"color: red\" for el in row])\n",
    "styled_df = styled_df.set_table_attributes(\"style='display:inline'\")\n",
    "styled_m0 = p_margin[nm_0].to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_m1 = p_margin[nm_1].to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_df._repr_html_() \n",
    "             + styled_m0._repr_html_()\n",
    "             + styled_m1._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that 4 of the 9 entries have probability 0. This means no records with this combination of categories are contained in the data. Given that the total dataset is quite large, it is reasonable that these observations are not missing by chance but are missing because these combinations are impossible. This hunch can be justified with some background knowledge about disability insurance. SSA here means Social Security Award. To claim disability benefits [\"awards\"](https://www.ssa.gov/oact/progdata/awardDef.html) from the US Social Security Administration, claimants have to undergo a procedure to decide whether their claims are justified or not. The result of this procedure, i.e. claim accepted or not, is quite informative for the status of the insured with respect to other benefit claims, such as a claim under a group long term disability policy. With this background, it becomes quite clear that the zeros are not missing at random. If the original award status is known to be N (=No) the award can not be updated or unknown, because there is nothing to update or know in the first place. The same with a U (=Unknown) original status. The update then can only be \"Unknown\" as well, because if it were otherwise (\"No\", \"Yes\"), there has to be a known original award.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distribution assuming independent margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product probabilities are found by multiplication of the marginal probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.107026Z",
     "iopub.status.idle": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply": "2024-11-13T16:34:33.107026Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.107026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Original_SSA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.028884</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.078550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.044803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.201454</td>\n",
       "      <td>0.066915</td>\n",
       "      <td>0.547854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Updated_SSA         No   Unknown       Yes\n",
       "Original_SSA                              \n",
       "N             0.028884  0.009594  0.078550\n",
       "U             0.016475  0.005472  0.044803\n",
       "Y             0.201454  0.066915  0.547854"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multiindex for broadcasting\n",
    "midx_prod = pd.MultiIndex.from_product([p_margin[nm_0].index,p_margin[nm_1].index])\n",
    "\n",
    "# broadcast resp. reindex and multiply\n",
    "p_indep =p_margin[nm_0].reindex(midx_prod, level=0).multiply(p_margin[nm_1])\n",
    "p_indep.name = \"p_indep\"\n",
    "p_indep.index.names = [nm_0, nm_1]\n",
    "display(p_indep.unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that those probabilities are quite different from the observed probabilities. It is not only that previous zero probabilities have been filled with non-zero values, but all other probabilies have changed as well. For example \"(N, No)\" has changed from 11.7% observed to 2.8% for independent. This is one of the two big problems with PDPs. If the inputs are dependent, PDPs rely on \"artificial\" independent joint probabilities, which are unrelated to anything in the real world. In our use case, they assign non-zero probabilities to impossible events, and distort the probabilities of the observed events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plain-vanilla logistic regression model is fitted. The reader should notice that a logistic model predicts probabilities, in this case the probability of recovery. This probability is completely different from the probabilities, which were calculated in the sections above. Those were the probabilities, or empirical frequencies, of the values of the inputs, the variables \"Original_SSA\" and \"Updated_SSA\" in the data. It is somewhat unfortunate and purely coincidental, that the dependent variable in this regression example is also a probability. This is nowhere relevant, neither for the calculations nor for the interpretation, and can be ignored safely by the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.107026Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "alllevels = [sorted(data[vnm].unique().tolist()) for vnm in [nm_0, nm_1]]\n",
    "\n",
    "# perform one hot encoding for the selected inputs in alllevels \n",
    "ohe_coding = ColumnTransformer(\n",
    "    [(\"\", OneHotEncoder(\n",
    "            drop=\"first\",\n",
    "            dtype=int,\n",
    "            sparse_output=False, \n",
    "            categories=alllevels),\n",
    "        [nm_0, nm_1])],\n",
    "    remainder=\"drop\", verbose_feature_names_out=False)\n",
    "\n",
    "# set up encoding and fit as a pipeline\n",
    "rf = Pipeline(\n",
    "    [   (\"preprocess\", ohe_coding),\n",
    "        (\"classifier\", LogisticRegression(penalty=None, fit_intercept=True))])\n",
    "\n",
    "# since this example is not concerned about prediction quality or\n",
    "# overfitting no train/test split is made and all data used for fit  \n",
    "xtrain = data[[nm_0, nm_1]]\n",
    "ytrain = data[\"Recovery\"]\n",
    "\n",
    "rf.fit(xtrain, ytrain)\n",
    "tmp = p_indep.index.to_frame()\n",
    "\n",
    "# put the fitted model ouputs, i.e. the predicted probabilities, into a Series\n",
    "predictions = pd.Series(rf.predict_proba(tmp)[:,1], index=p_indep.index)\n",
    "predictions.name = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It always makes sense to compare model predictions with the actual data. An estimate for the probability of recovery for each combination of categories is the average of the observed recoveries in this class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by the categorical variables and calculate the mean for each group.\n",
    "actual = data.groupby([nm_0,nm_1], observed=True)[\"Recovery\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare predictions with the estimates from above. Note that the predicted and actual values are quite close. This is no surprise, there is more than enough data available to determine the 1+2+2=5 parameters of the logistic regression. But, note also, that the model can make \"predictions\", or maybe more appropriate can produce values, for the impossible combinations. And, while it makes sense to assign a definite probability, i.e. zero, to these combinations, it makes no sense to assign any \"Actual\" recoveries to them, not even zero. This is why NaNs have to be filled in for the observed recoveries at these combinations.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f1838\" style='display:inline'>\n",
       "  <caption><b>Predictions<b></caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Updated_SSA</th>\n",
       "      <th id=\"T_f1838_level0_col0\" class=\"col_heading level0 col0\" >No</th>\n",
       "      <th id=\"T_f1838_level0_col1\" class=\"col_heading level0 col1\" >Unknown</th>\n",
       "      <th id=\"T_f1838_level0_col2\" class=\"col_heading level0 col2\" >Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Original_SSA</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f1838_level0_row0\" class=\"row_heading level0 row0\" >N</th>\n",
       "      <td id=\"T_f1838_row0_col0\" class=\"data row0 col0\" >0.044172</td>\n",
       "      <td id=\"T_f1838_row0_col1\" class=\"data row0 col1\" >0.054167</td>\n",
       "      <td id=\"T_f1838_row0_col2\" class=\"data row0 col2\" >0.058865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1838_level0_row1\" class=\"row_heading level0 row1\" >U</th>\n",
       "      <td id=\"T_f1838_row1_col0\" class=\"data row1 col0\" >0.071542</td>\n",
       "      <td id=\"T_f1838_row1_col1\" class=\"data row1 col1\" >0.087165</td>\n",
       "      <td id=\"T_f1838_row1_col2\" class=\"data row1 col2\" >0.094440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1838_level0_row2\" class=\"row_heading level0 row2\" >Y</th>\n",
       "      <td id=\"T_f1838_row2_col0\" class=\"data row2 col0\" >0.003093</td>\n",
       "      <td id=\"T_f1838_row2_col1\" class=\"data row2 col1\" >0.003830</td>\n",
       "      <td id=\"T_f1838_row2_col2\" class=\"data row2 col2\" >0.004182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a6b5e\" style='display:inline'>\n",
       "  <caption><b>Actual<b></caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Updated_SSA</th>\n",
       "      <th id=\"T_a6b5e_level0_col0\" class=\"col_heading level0 col0\" >No</th>\n",
       "      <th id=\"T_a6b5e_level0_col1\" class=\"col_heading level0 col1\" >Unknown</th>\n",
       "      <th id=\"T_a6b5e_level0_col2\" class=\"col_heading level0 col2\" >Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Original_SSA</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a6b5e_level0_row0\" class=\"row_heading level0 row0\" >N</th>\n",
       "      <td id=\"T_a6b5e_row0_col0\" class=\"data row0 col0\" >0.044225</td>\n",
       "      <td id=\"T_a6b5e_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_a6b5e_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6b5e_level0_row1\" class=\"row_heading level0 row1\" >U</th>\n",
       "      <td id=\"T_a6b5e_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_a6b5e_row1_col1\" class=\"data row1 col1\" >0.087167</td>\n",
       "      <td id=\"T_a6b5e_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a6b5e_level0_row2\" class=\"row_heading level0 row2\" >Y</th>\n",
       "      <td id=\"T_a6b5e_row2_col0\" class=\"data row2 col0\" >0.002952</td>\n",
       "      <td id=\"T_a6b5e_row2_col1\" class=\"data row2 col1\" >0.004880</td>\n",
       "      <td id=\"T_a6b5e_row2_col2\" class=\"data row2 col2\" >0.004186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = predictions.unstack().style\n",
    "df1 = df1.set_table_attributes(\"style='display:inline'\").set_caption(\"<b>Predictions<b>\")\n",
    "df2 = actual.unstack().style\n",
    "df2 = df2.set_table_attributes(\"style='display:inline'\").set_caption(\"<b>Actual<b>\")\n",
    "display_html(df1._repr_html_() + df2._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above demonstrates the second big problem with PDPs for dependent data. They evaluate the model on combinations, which are impossible, as the case is here and use these outputs for the result. Since the models have not been trained on these data points, there is absolutely no assurance on the resulting value. It depends on \"wild\" extrapolation, which is unconstrained by data. In the categorical case, even implied assurances, such as smoothness, are not available, because, in general, the evaluation at one discrete data point has no informative value on another discrete data point.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We derive, and later compare, four different ways to estimate marginal functions:\n",
    "* SKL: The implementation of PDPs in Scikit-learn for categorical inputs.\n",
    "* Permutation: The estimate of the PDP based on the permutation of one input. This is the original PDP definition.\n",
    "* Independent: A direct calculation using independent marginal probabilities.\n",
    "* Observed: The alternative to PDPs using conditional expectations based on the actually observed joint probability of the inputs.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value\n",
       "categories   variable          \n",
       "Original_SSA N         0.054854\n",
       "             U         0.088192\n",
       "             Y         0.003884\n",
       "Updated_SSA  No        0.012469\n",
       "             Unknown   0.015283\n",
       "             Yes       0.016606"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = partial_dependence(rf, xtrain, nm_0,\n",
    "                            categorical_features=[nm_0, nm_1],\n",
    "                            feature_names=[nm_0, nm_1],\n",
    "                            response_method=\"predict_proba\",\n",
    "                            method=\"brute\")\n",
    "res_0 = pd.Series(tmp[\"average\"][0], index=tmp[\"grid_values\"])\n",
    "tmp = partial_dependence(rf, xtrain, nm_1,\n",
    "                            categorical_features=[nm_0, nm_1],\n",
    "                            feature_names=[nm_0, nm_1],\n",
    "                            response_method=\"predict_proba\",\n",
    "                            method=\"brute\")\n",
    "res_1 = pd.Series(tmp[\"average\"][0], index=tmp[\"grid_values\"])\n",
    "\n",
    "pdp_skl = pd.concat([res_0, res_1], keys=[nm_0, nm_1]).to_frame()\n",
    "pdp_skl.columns = [\"value\"]\n",
    "pdp_skl.index.names = [\"categories\", \"variable\"]\n",
    "pdp_skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.054849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.088197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.012475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.015247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.016608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value\n",
       "categories   variable          \n",
       "Original_SSA N         0.054849\n",
       "             U         0.088197\n",
       "             Y         0.003884\n",
       "Updated_SSA  No        0.012475\n",
       "             Unknown   0.015247\n",
       "             Yes       0.016608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data with permutation of a variable\n",
    "permudata = data.copy()\n",
    "permudata[nm_0] = pd.Categorical(permudata[nm_0].sample(frac=1))\n",
    "# make prediction on permuted inputs\n",
    "permudata[\"f\"] = rf.predict_proba(permudata)[:,1]\n",
    "# integrals are obtained by averaging, \n",
    "# mean is here OK because data is (assumed to be) iid\n",
    "res_0 = permudata.groupby(nm_0, observed=True)[\"f\"].mean()\n",
    "res_1 = permudata.groupby(nm_1, observed=True)[\"f\"].mean()\n",
    "\n",
    "pdp_permutation = pd.concat([res_0, res_1], keys=[nm_0, nm_1]).to_frame()\n",
    "pdp_permutation.columns = [\"value\"]\n",
    "pdp_permutation.index.names = [\"categories\", \"variable\"]\n",
    "pdp_permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two PDPs $f_A$ and $f_B$ are just the conditional expectations of the prediction with respect to the two variables using `p_indep`, i.e. the probabilities with independent margins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value\n",
       "categories   variable          \n",
       "Original_SSA N         0.054854\n",
       "             U         0.088192\n",
       "             Y         0.003884\n",
       "Updated_SSA  No        0.012469\n",
       "             Unknown   0.015283\n",
       "             Yes       0.016606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_weighted = predictions.multiply(p_indep, axis=0)\n",
    "res_0 = f_weighted.groupby([nm_0]).sum().divide(p_margin[nm_0], axis=0) \n",
    "res_1 = f_weighted.groupby([nm_1]).sum().divide(p_margin[nm_1], axis=0)\n",
    "\n",
    "pdp_indep = pd.concat([res_0, res_1], keys=[nm_0, nm_1]).to_frame()\n",
    "pdp_indep.columns = [\"value\"]\n",
    "pdp_indep.index.names = [\"categories\", \"variable\"]\n",
    "pdp_indep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the same calculation as above, but the conditional expectation functions now use the observed joint distribution, i.e. ``p_observed``, instead of the independent margins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.113106Z",
     "iopub.status.idle": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply": "2024-11-13T16:34:33.113106Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.113106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.044172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.087165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.004002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.071682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.004182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value\n",
       "categories   variable          \n",
       "Original_SSA N         0.044172\n",
       "             U         0.087165\n",
       "             Y         0.004002\n",
       "Updated_SSA  No        0.022571\n",
       "             Unknown   0.071682\n",
       "             Yes       0.004182"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_weighted = predictions.multiply(p_observed, axis=0)\n",
    "res_0 = f_weighted.groupby([nm_0]).sum().divide(p_margin[nm_0], axis=0) \n",
    "res_1 = f_weighted.groupby([nm_1]).sum().divide(p_margin[nm_1], axis=0)\n",
    "\n",
    "pdp_observed = pd.concat([res_0, res_1], keys=[nm_0, nm_1]).to_frame()\n",
    "pdp_observed.columns = [\"value\"]\n",
    "pdp_observed.index.names = [\"categories\", \"variable\"]\n",
    "pdp_observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.119613Z",
     "iopub.status.idle": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.119613Z"
    }
   },
   "outputs": [],
   "source": [
    "pdp = pd.concat([pdp_skl, pdp_permutation, pdp_indep, pdp_observed], \n",
    "                keys=[\"SKL\", \"permutation\", \"PDP\", \"Exact\"], names=[\"method\"])\n",
    "pdp = pdp.reorder_levels([\"method\", \"categories\", \"variable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first comparison is between \"SKL\", i.e. the method used in Scikit-learn and the explicit calculation using independent probabilities \"PDP\". It shows that the results are indeed identical. In contrast to estimates for PDP involving permutations (as discussed next) the sklearn method uses uses the conditional expectation under independent probabilities. To quote from the documentation of version 1.5.2 of the (internal) function `_partial_dependence_brute` in `sklearn.inspection`:\n",
    "> ...for each value in `grid`, the method will average the prediction of each\n",
    "        sample from `X` having that grid value for `features`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.119613Z",
     "iopub.status.idle": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.119613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>SKL</th>\n",
       "      <th>PDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.054854</td>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.088192</td>\n",
       "      <td>0.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.015283</td>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          value          \n",
       "method                      SKL       PDP\n",
       "categories   variable                    \n",
       "Original_SSA N         0.054854  0.054854\n",
       "             U         0.088192  0.088192\n",
       "             Y         0.003884  0.003884\n",
       "Updated_SSA  No        0.012469  0.012469\n",
       "             Unknown   0.015283  0.015283\n",
       "             Yes       0.016606  0.016606"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pdp.loc[[\"SKL\", \"PDP\"]]\n",
    "tmp.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare the permutation method, which is the method by which PDPs are usually defined, with the exact calculation. The permutation method involves sampling, and we cannot expect exact equality, but the values are convincingly close. One can conclude, that, indeed, the integration by permutation is an approximation to the calculation based on conditional expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.119613Z",
     "iopub.status.idle": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.119613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>permutation</th>\n",
       "      <th>PDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Original_SSA</th>\n",
       "      <th>N</th>\n",
       "      <td>0.054849</td>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Updated_SSA</th>\n",
       "      <th>No</th>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            value          \n",
       "method                permutation       PDP\n",
       "categories   variable                      \n",
       "Original_SSA N           0.054849  0.054854\n",
       "             U           0.088197  0.088192\n",
       "             Y           0.003884  0.003884\n",
       "Updated_SSA  No          0.012475  0.012469\n",
       "             Unknown     0.015247  0.015283\n",
       "             Yes         0.016608  0.016606"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pdp.loc[[\"permutation\", \"PDP\"]]\n",
    "tmp.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the marginal functions under observed and independent probabilities. There are some striking differences. Especially, the \"Updated_SSA\" values are apart with a factor of two to five! To further illustrate what is going on (or going wrong?) the actual recoveries cumulated over the margins are included. Obviously, the calculation using the observed probabilities and only actually occurring data for the predictions is much closer to actual values than the PDP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-13T16:34:33.119613Z",
     "iopub.status.idle": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply": "2024-11-13T16:34:33.119613Z",
     "shell.execute_reply.started": "2024-11-13T16:34:33.119613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ec72a\">\n",
       "  <caption><b>Comparison between PDP, exact calculation and Actuals<b></caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec72a_level0_col0\" class=\"col_heading level0 col0\" >PDP</th>\n",
       "      <th id=\"T_ec72a_level0_col1\" class=\"col_heading level0 col1\" >Exact</th>\n",
       "      <th id=\"T_ec72a_level0_col2\" class=\"col_heading level0 col2\" >Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">Original_SSA</th>\n",
       "      <th id=\"T_ec72a_level1_row0\" class=\"row_heading level1 row0\" >N</th>\n",
       "      <td id=\"T_ec72a_row0_col0\" class=\"data row0 col0\" >0.054854</td>\n",
       "      <td id=\"T_ec72a_row0_col1\" class=\"data row0 col1\" >0.044172</td>\n",
       "      <td id=\"T_ec72a_row0_col2\" class=\"data row0 col2\" >0.044225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level1_row1\" class=\"row_heading level1 row1\" >U</th>\n",
       "      <td id=\"T_ec72a_row1_col0\" class=\"data row1 col0\" >0.088192</td>\n",
       "      <td id=\"T_ec72a_row1_col1\" class=\"data row1 col1\" >0.087165</td>\n",
       "      <td id=\"T_ec72a_row1_col2\" class=\"data row1 col2\" >0.087167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level1_row2\" class=\"row_heading level1 row2\" >Y</th>\n",
       "      <td id=\"T_ec72a_row2_col0\" class=\"data row2 col0\" >0.003884</td>\n",
       "      <td id=\"T_ec72a_row2_col1\" class=\"data row2 col1\" >0.004002</td>\n",
       "      <td id=\"T_ec72a_row2_col2\" class=\"data row2 col2\" >0.004003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"3\">Updated_SSA</th>\n",
       "      <th id=\"T_ec72a_level1_row3\" class=\"row_heading level1 row3\" >No</th>\n",
       "      <td id=\"T_ec72a_row3_col0\" class=\"data row3 col0\" >0.012469</td>\n",
       "      <td id=\"T_ec72a_row3_col1\" class=\"data row3 col1\" >0.022571</td>\n",
       "      <td id=\"T_ec72a_row3_col2\" class=\"data row3 col2\" >0.022522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level1_row4\" class=\"row_heading level1 row4\" >Unknown</th>\n",
       "      <td id=\"T_ec72a_row4_col0\" class=\"data row4 col0\" >0.015283</td>\n",
       "      <td id=\"T_ec72a_row4_col1\" class=\"data row4 col1\" >0.071682</td>\n",
       "      <td id=\"T_ec72a_row4_col2\" class=\"data row4 col2\" >0.071878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec72a_level1_row5\" class=\"row_heading level1 row5\" >Yes</th>\n",
       "      <td id=\"T_ec72a_row5_col0\" class=\"data row5 col0\" >0.016606</td>\n",
       "      <td id=\"T_ec72a_row5_col1\" class=\"data row5 col1\" >0.004182</td>\n",
       "      <td id=\"T_ec72a_row5_col2\" class=\"data row5 col2\" >0.004186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17f41a1e1e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = p_observed.multiply(actual).dropna()\n",
    "res_0 = tmp.groupby(nm_0).sum().divide(p_margin[nm_0])\n",
    "res_1 = tmp.groupby(nm_1).sum().divide(p_margin[nm_1])\n",
    "\n",
    "pdp_actual = pd.concat([res_0, res_1], keys=[nm_0, nm_1])\n",
    "pdp_actual.name = \"Actual\"\n",
    "pdp_actual.index.names = [\"variable\", \"categories\"]\n",
    "tmp = pdp.loc[[\"PDP\", \"Exact\"]].unstack([\"method\"]).droplevel(0, axis=1)\n",
    "pd.concat([tmp, pdp_actual], axis=1).style.set_caption(\n",
    "    \"<b>Comparison between PDP, exact calculation and Actuals<b>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We claim that PDPs for dependent inputs may be misleading, and the notebook demonstrates this with a simple case study. PDPs on dependent inputs may be misleading because:\n",
    "1. They use distorted probabilities, i.e. probabilities which are different from the probabilities of the phenomenon of interest.\n",
    "2. They may incorporate model evaluations from inputs which are logically impossible.\n",
    "\n",
    "This has the following consequences:\n",
    "* The PDPs of models with very similar predictive performance and structure may produce very different PDPs, suggesting differences which in reality do not exist.\n",
    "* Either the PDP cannot be compared to actual data (for impossible points) or the comparison may be distorted by the different underlying probabilities, i.e. observed ones for the data, independent ones for the PDP. This may suggest lack of fit, although the model fits well or may hide lack of fit.\n",
    "\n",
    "The last point has even inspired adversarial attacks. In those attacks the extrapolation to unseen data is exploited to manipulate the PDP, for example to hide a dependence of the model on undesirable, e.g. protected features.\n",
    "\n",
    "All these issues remain, even when the independent data does not include impossible combinations. If the observed joint distribution is not independent, it will be different from the independent distribution and will distort the averaging involved in the calculation of the PDP.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better ways to define marginal functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to avoid problems with impossible data, is not having it in the first place. The fact that 4 out of 9 possibilities for the SSA variables are impossible, is a consequence of the unfortunate encoding, using two categorical variables. Without loss of information or any reduction in explainability, one could code the five possible combinations into one single variable \"SSA\" with 5 categories labelled: (N, No), (U, Unknown), (Y,No), (Y,Unknown) and (Y, Yes). This would eliminate ALL the problems discussed in this notebook for this variable.\n",
    "\n",
    "The next best thing is to use conditional expectations based on the real, i.e. observed, probabilities. This is better than PDPs because:\n",
    "* It uses only data which is relevant for the use case, not artificially constructed probabilities and model evaluations.\n",
    "* It can be compared to raw averages directly derived from the data.\n",
    "* Even though you have to calculate the conditional expectations yourself and cannot use the standard implementations of PDP, it is really easy to do this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLTD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
