{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Simon-Style -->\n",
    "<p style=\"font-size:19px; text-align:left; margin-top:    15px;\"><i>German Association of Actuaries (DAV) — Working Group \"Explainable Artificial Intelligence\"</i></p>\n",
    "<p style=\"font-size:25px; text-align:left; margin-bottom: 15px\"><b>Use Case SOA GLTD Experience Study:<br>\n",
    "Tree Model - Hyper Parameters\n",
    "</b></p>\n",
    "<p style=\"font-size:19px; text-align:left; margin-bottom: 15px; margin-bottom: 15px\">Guido Grützner (<a href=\"mailto:guido.gruetzner@quantakt.com\">guido.gruetzner@quantakt.com</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This report performs a grid search for tuning parameter `max_depth` for DecisionTreeClassifier Trees. Optimal hyperparameters are pct-dependent. See the text before the last cell of \"Initialisation\" below for more information on `pct`.\n",
    "\n",
    "This notebook will take roughly 5 min to run with the given search grid and a choice of `pct=0.3` for the amount of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:32:53.302998Z",
     "iopub.status.busy": "2025-01-07T13:32:53.302998Z",
     "iopub.status.idle": "2025-01-07T13:32:54.220951Z",
     "shell.execute_reply": "2025-01-07T13:32:54.220951Z",
     "shell.execute_reply.started": "2025-01-07T13:32:53.302998Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import \\\n",
    "    GroupShuffleSplit, GridSearchCV\n",
    "\n",
    "import gltd_utilities\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adapt the path for the data file in the call of `load_gltd_data`, if necessary.\n",
    "* Adapt `pct` to your requirements for anything between  $0.05\\leq pct\\leq1$. \n",
    "* Input 1 uses all data available, lower numbers the respective fraction. Below 0.05 predictions become somewhat volatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:32:54.220951Z",
     "iopub.status.busy": "2025-01-07T13:32:54.220951Z",
     "iopub.status.idle": "2025-01-07T13:32:54.692340Z",
     "shell.execute_reply": "2025-01-07T13:32:54.692340Z",
     "shell.execute_reply.started": "2025-01-07T13:32:54.220951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156700121105998886695440653718163913769'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X, Y, ID, nm_cat, nm_num, seed, rng) = gltd_utilities.load_gltd_data(\n",
    "                                            \"./\", pct=0.3)\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:32:54.692845Z",
     "iopub.status.busy": "2025-01-07T13:32:54.692845Z",
     "iopub.status.idle": "2025-01-07T13:33:01.926683Z",
     "shell.execute_reply": "2025-01-07T13:33:01.925175Z",
     "shell.execute_reply.started": "2025-01-07T13:32:54.692845Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "        [(\"\", OneHotEncoder(drop=\"first\", sparse_output=False, dtype=int),\n",
    "                        nm_cat)], \n",
    "        remainder=\"passthrough\", verbose_feature_names_out=False)\n",
    "\n",
    "X_ohe = ct.fit_transform(X)\n",
    "\n",
    "train_indx, test_indx = next(\n",
    "    GroupShuffleSplit(random_state=rng.integers(low=0, high=1000)).split(X_ohe, groups=ID))\n",
    "xtrain, xtest = X_ohe[train_indx, :], X_ohe[test_indx,:] \n",
    "\n",
    "ytrain, ytest = Y.iloc[train_indx], Y.iloc[test_indx]\n",
    "idtrain, idtest = ID.iloc[train_indx], ID.iloc[test_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:33:01.926683Z",
     "iopub.status.busy": "2025-01-07T13:33:01.926683Z",
     "iopub.status.idle": "2025-01-07T13:39:00.079226Z",
     "shell.execute_reply": "2025-01-07T13:39:00.079226Z",
     "shell.execute_reply.started": "2025-01-07T13:33:01.926683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=6;, score=-0.056 total time=  18.8s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=6;, score=-0.055 total time=  19.4s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=6;, score=-0.055 total time=  18.6s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=6;, score=-0.055 total time=  18.6s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=6;, score=-0.054 total time=  18.9s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=7;, score=-0.056 total time=  22.0s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=7;, score=-0.055 total time=  21.9s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=7;, score=-0.056 total time=  23.4s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=7;, score=-0.055 total time=  22.7s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=7;, score=-0.056 total time=  22.8s\n",
      "[CV 1/5] END ..criterion=log_loss, max_depth=8;, score=-0.059 total time=  25.8s\n",
      "[CV 2/5] END ..criterion=log_loss, max_depth=8;, score=-0.058 total time=  25.4s\n",
      "[CV 3/5] END ..criterion=log_loss, max_depth=8;, score=-0.059 total time=  24.7s\n",
      "[CV 4/5] END ..criterion=log_loss, max_depth=8;, score=-0.057 total time=  24.7s\n",
      "[CV 5/5] END ..criterion=log_loss, max_depth=8;, score=-0.058 total time=  23.9s\n",
      "Time it took: 6.0min.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.791785</td>\n",
       "      <td>0.300730</td>\n",
       "      <td>0.187245</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 6}</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>-0.055065</td>\n",
       "      <td>-0.054993</td>\n",
       "      <td>-0.054555</td>\n",
       "      <td>-0.054376</td>\n",
       "      <td>-0.055029</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.470687</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.177680</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 7}</td>\n",
       "      <td>-0.056007</td>\n",
       "      <td>-0.055429</td>\n",
       "      <td>-0.055568</td>\n",
       "      <td>-0.054629</td>\n",
       "      <td>-0.055721</td>\n",
       "      <td>-0.055471</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.791498</td>\n",
       "      <td>0.636613</td>\n",
       "      <td>0.194141</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>8</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': 8}</td>\n",
       "      <td>-0.058606</td>\n",
       "      <td>-0.057964</td>\n",
       "      <td>-0.059386</td>\n",
       "      <td>-0.057487</td>\n",
       "      <td>-0.058476</td>\n",
       "      <td>-0.058384</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      18.791785      0.300730         0.187245        0.013073   \n",
       "1      22.470687      0.549937         0.177680        0.006303   \n",
       "2      24.791498      0.636613         0.194141        0.008316   \n",
       "\n",
       "  param_criterion param_max_depth                                     params  \\\n",
       "0        log_loss               6  {'criterion': 'log_loss', 'max_depth': 6}   \n",
       "1        log_loss               7  {'criterion': 'log_loss', 'max_depth': 7}   \n",
       "2        log_loss               8  {'criterion': 'log_loss', 'max_depth': 8}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -0.056156          -0.055065          -0.054993          -0.054555   \n",
       "1          -0.056007          -0.055429          -0.055568          -0.054629   \n",
       "2          -0.058606          -0.057964          -0.059386          -0.057487   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0          -0.054376        -0.055029        0.000621                1  \n",
       "1          -0.055721        -0.055471        0.000463                2  \n",
       "2          -0.058476        -0.058384        0.000639                3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "pgrid = {\"max_depth\": [6, 7, 8], \"criterion\": [\"log_loss\"]}\n",
    "\n",
    "md = DecisionTreeClassifier(random_state=rng.integers(low=0, high=1000))\n",
    "\n",
    "cv = GroupShuffleSplit(n_splits=5,\n",
    "                            random_state=rng.integers(low=0, high=1000))\n",
    "tic = time.time()\n",
    "clf = GridSearchCV(estimator=md, param_grid=pgrid, cv=cv, \n",
    "                   scoring=\"neg_log_loss\", verbose=4)\n",
    "\n",
    "clf.fit(xtrain, ytrain, groups=idtrain)\n",
    "print(f\"Time it took: {np.ceil((time.time() - tic)/60)}min.\")\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:39:00.079226Z",
     "iopub.status.busy": "2025-01-07T13:39:00.079226Z",
     "iopub.status.idle": "2025-01-07T13:39:00.088816Z",
     "shell.execute_reply": "2025-01-07T13:39:00.088816Z",
     "shell.execute_reply.started": "2025-01-07T13:39:00.079226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'log_loss', 'max_depth': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:39:00.088816Z",
     "iopub.status.busy": "2025-01-07T13:39:00.088816Z",
     "iopub.status.idle": "2025-01-07T13:39:00.099465Z",
     "shell.execute_reply": "2025-01-07T13:39:00.099465Z",
     "shell.execute_reply.started": "2025-01-07T13:39:00.088816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05502919947828779"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By their construction, tree models tend to create probability estimates biased towards zero or one. Of course, both are impossible values, given the use case. This is partially mitigated by the loss function, which we use. Indeed, the number of zero and one predictions is limited, given the size of the data. This acceptable amount of calibration is further evidenced by the calibration diagram in \"ana_fit\".    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:39:00.099465Z",
     "iopub.status.busy": "2025-01-07T13:39:00.099465Z",
     "iopub.status.idle": "2025-01-07T13:39:01.048813Z",
     "shell.execute_reply": "2025-01-07T13:39:01.048813Z",
     "shell.execute_reply.started": "2025-01-07T13:39:00.099465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exact zero values in train: 8394\n",
      "Number of exact zero values in test: 2058\n"
     ]
    }
   ],
   "source": [
    "res = clf.best_estimator_.predict_proba(xtrain)[:,1]\n",
    "if np.isnan(res).any():\n",
    "    raise ValueError(\"Dreaded NaNs!\")\n",
    "if (res <= 0).any():\n",
    "    tt = sum(res == 0)\n",
    "    print(f\"Number of exact zero values in train: {tt}\")\n",
    "    if (res < 0).any():\n",
    "        raise ValueError(\"Dreaded Negatives!\")\n",
    "if (res >= 1).any():\n",
    "    tt = sum(res == 1)\n",
    "    print(f\"Number of exact one values in train: {tt}\")\n",
    "    if (res > 1).any():\n",
    "        raise ValueError(\"Dreaded Larger-Than-Ones!\")\n",
    "\n",
    "res = clf.best_estimator_.predict_proba(xtest)[:,1]\n",
    "if np.isnan(res).any():\n",
    "    raise ValueError(\"Dreaded NaNs!\")\n",
    "if (res <= 0).any():\n",
    "    tt = sum(res == 0)\n",
    "    print(f\"Number of exact zero values in test: {tt}\")\n",
    "    if (res < 0).any():\n",
    "        raise ValueError(\"Dreaded Negatives!\")\n",
    "if (res >= 1).any():\n",
    "    tt = sum(res == 1)\n",
    "    print(f\"Number of exact one values in test: {tt}\")\n",
    "    if (res > 1).any():\n",
    "        raise ValueError(\"Dreaded Larger-Than-Ones!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
