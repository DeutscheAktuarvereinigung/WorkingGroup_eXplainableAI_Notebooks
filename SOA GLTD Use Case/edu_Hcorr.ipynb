{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Simon-Style -->\n",
    "<p style=\"font-size:19px; text-align:left; margin-top:    15px;\"><i>German Association of Actuaries (DAV) — Working Group \"Explainable Artificial Intelligence\"</i></p>\n",
    "<p style=\"font-size:25px; text-align:left; margin-bottom: 15px\"><b>Use Case SOA GLTD Experience Study:<br>\n",
    "USE CASE GLTD - H-statistic with dependent categorical inputs\n",
    "</b></p>\n",
    "<p style=\"font-size:19px; text-align:left; margin-bottom: 15px; margin-bottom: 15px\">Guido Grützner (<a href=\"mailto:guido.gruetzner@quantakt.com\">guido.gruetzner@quantakt.com</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The identification of interactions is an important goal when trying to understand models which result from a supervised learning task. One standard approach to do this is the H-statistic [see e.g. [Molnar]](https://christophm.github.io/interpretable-ml-book/interaction.html#theory-friedmans-h-statistic). In this notebook we will \n",
    "* explain why the H-statistics makes sense under the assumption of independent inputs,\n",
    "* and propose an alternative approach, the correlated H-statistic, for dependent, categorical inputs.\n",
    "\n",
    "We will show and explain that this alternative has the following properties\n",
    "* The correlated H-statistic only uses the actual observed joint probabilities, not probabilities from independent margins.\n",
    "* It not only works for fitted models but can also provide information on the raw data.\n",
    "* It is very fast to compute, even for a sizeable number of inputs, which may have a large number of categories.\n",
    "\n",
    "Together with theoretical considerations, this notebook provides a (didactic) reference implementation by way of a simple example from the SOA GLTD dataset. This is the dataset which is used in all notebooks of the Use Case GLTD. Further background on this dataset is available in the other notebooks of this Use Case and the original SOA experience study (see [2019 Group Long-Term Disability Experience Study Preliminary Report](https://www.soa.org/4a7e84/globalassets/assets/files/resources/experience-studies/2019/2019-gltd-study-report.pdf)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition and background for the H-statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H-statistic is normally introduced by its sampling estimator. For the sample $(a_k,b_k)_{k=1}^N$ from an independent pair of random variables $(A,B)$ and a zero mean, i.e. centred function $f$:\n",
    "$$ H=\\frac{\\sum_{k=1}^N \\big(f(a_k,b_k) - f_A(a_k) - f_B(b_k)\\big)^2}{\\sum_{k=1}^N \\big(f(a_k,b_k)\\big)^2}$$\n",
    "where $f_A$ and $f_B$ are the partial dependence functions of $f$, i.e. $f_A(a) = \\frac 1 N \\sum_{k=1}^N f(a,b_k)$ and $f_B(b) = \\frac 1 N \\sum_{k=1}^N f(a_k,b).$ \n",
    "\n",
    "But the motivation behind the H-statistic is best understood in the broader context of the functional ANOVA decomposition. If a function $f$ of an independent pair of random variables $(A,B)$ has finite variance, then the random variable $f(A,B)$ allows the decomposition:\n",
    "$$ f(a,b) = f_0 + f_A(a) + f_B(b) + f_{A,B}(a,b),$$\n",
    "where \n",
    "* $f_0 = \\mathbb{E}_{A,B}[f(A,B)]$ is a constant function.\n",
    "* $f_A(a) = \\mathbb{E}_B[f(a,B)] - f_0$ and $f_B(b) = \\mathbb{E}_A[f(A,b)] - f_0$ are the partial dependence in particular univariate, functions,\n",
    "* and $f_{A,B}(a,b) = f(a,b) - f_0 - f_A(a) - f_B(b)$ is a bivariate function.\n",
    "\n",
    "This decomposition has some appealing properties\n",
    "1. it is unique,\n",
    "2. all summands are uncorrelated,\n",
    "3. the sum $f_0 + f_A(a) + f_B(b)$ is the best approximation to $f$ by additive functions in the least squares (i.e. ${L}^2$ ) sense.\n",
    "\n",
    "From 2. above it is clear that the variance $\\mathbb{V}[f]$ allows the decomposition \n",
    "$$ \\mathbb{V}[f] = \\mathbb{V}[f_A] + \\mathbb{V}[f_B] + \\mathbb{V}[f_{A,B}]$$\n",
    "and 3. motivates the characterisation of $f_{A,B}$ as the \"pure interaction term\".  Acknowledging these two facts, the H-statistic is simply \n",
    "$$ H=\\frac{\\mathbb{V}[f_{A,B}]}{\\mathbb{V}[f]},$$\n",
    "which can be interpreted as the relative amount of variance explained by the pure interaction term. Here, and in this whole report, all stochastic quantities are always understood with respect to the empirical probability distribution defined by the observations. In particular, we do not distinguish between population quantities and sample estimates.\n",
    "\n",
    "The functional ANOVA decomposition works in the same way for multivariate inputs. Of course, in the multivariate case, there will be one univariate component for each input, an interaction term for each pair of inputs and higher order interactions, i.e. with three, four, ..., inputs as well. But, for the definition of the H-statistic, only pairs of inputs and the according bivariate decompositions are needed.\n",
    "\n",
    "A discussion of functional ANOVA can be found in [Saltelli](http://www.andreasaltelli.eu/file/repository/PUBLISHED_PAPER.pdf), while [Kuo et.al.](https://www.ams.org/journals/mcom/2010-79-270/S0025-5718-09-02319-9/S0025-5718-09-02319-9.pdf) provide detailed proofs in a Hilbert-Space setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with the H-statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H-statistic has two problems, one fundamental and one practical. The fundamental issue is the assumption of independence, which is rarely met for real data. A calculation based on independence distorts the true probabilities and leads to impossible data issues. For a case study and more explanations on this topic, see the notebook \"Case_Study_depPDP\". The practical issue is caused by the estimation based on samples. For one pair of inputs $O(N^2)$ function evaluations are required, which means that the calculation of all H-statistics for the interactions of $d$ inputs requires the order of $O(d^2N^2)$ function evaluations.\n",
    "\n",
    "The proposed remedy is somewhat obvious: Just use the true probabilities and conditional expectations instead of partial dependence functions. This avoids the distortion of the data generation process and avoids impossible data. The use of conditional expectations is possible, since all inputs are categorical. In this case, the calculation of conditional expectations is straightforward and can be implemented in a highly optimized manner using just a single evaluation of the model on the data. Furthermore, since no impossible data is involved, the statistics can be calculated already on the raw data, without requiring any model at all.\n",
    "\n",
    "But, if inputs are dependent, the functional ANOVA decomposition is no longer available. While one can still define the components, as above, just using conditional expectations, they will no longer be uncorrelated, which in turn means that an additive attribution of the variances to single components is no longer possible. But it is possible to carefully work around this problem, and come up with a weaker decomposition, which, nevertheless, is just sufficient to define a correlated H-statistic.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic concepts and their implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly define and implement the correlated H-statistic using linear algebra, we need to go from single functions, to vector spaces of functions and recognize the underlying geometry provided by the probability distribution. At the same time, we will try to demonstrate in examples how the mathematical concepts are reflected and ultimately implemented in code. For this purpose, we will rely on an example based on the GLTD use case. We use the same dataset and the same utility function to load the data as for the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:38.576306Z",
     "iopub.status.busy": "2024-07-29T18:36:38.576306Z",
     "iopub.status.idle": "2024-07-29T18:36:38.990758Z",
     "shell.execute_reply": "2024-07-29T18:36:38.990758Z",
     "shell.execute_reply.started": "2024-07-29T18:36:38.576306Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, display_html\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), '../report versions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import gltd_utilities\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:38.991761Z",
     "iopub.status.busy": "2024-07-29T18:36:38.990758Z",
     "iopub.status.idle": "2024-07-29T18:36:41.946077Z",
     "shell.execute_reply": "2024-07-29T18:36:41.944071Z",
     "shell.execute_reply.started": "2024-07-29T18:36:38.991761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'197746953433573068013957040465879210157'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X, Y, ID, nm_cat, nm_num, seed, rng) = gltd_utilities.load_gltd_data(\n",
    "                                            \"d:/tmp/GLTD data/\", pct=1)\n",
    "for vnm in nm_cat:\n",
    "    X[vnm] = X[vnm].cat.remove_unused_categories()\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all inputs are categorical, the space of functions of these categorical variables is a finite dimensional vector spaces. We demonstrate first how these functions can be understood and implemented as Pandas series with multi-indices. This is done using an extract consisting of just two input variables from the GLTD dataset, which we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:41.950079Z",
     "iopub.status.busy": "2024-07-29T18:36:41.948080Z",
     "iopub.status.idle": "2024-07-29T18:36:42.446753Z",
     "shell.execute_reply": "2024-07-29T18:36:42.446238Z",
     "shell.execute_reply.started": "2024-07-29T18:36:41.950079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6388739 observations in the data.\n",
      "Diagnosis_Category    category\n",
      "Gender                category\n",
      "Actual_Recoveries        int64\n",
      "dtype: object\n",
      "The variable `Diagnosis_Category` has the categories ['Circulatory', 'Maternity', 'other']\n",
      "The variable `Gender` has the categories ['F', 'M']\n",
      "The variable `Actual_Recoveries` takes the values [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# load a pair of inputs and observations from the data \n",
    "demodata = pd.concat([X[[\"Diagnosis_Category\", \"Gender\"]], Y], axis=1)\n",
    "# Simplify Diagnosis_Category because there are a lot of categories     \n",
    "demodata[\"Diagnosis_Category\"] = demodata[\"Diagnosis_Category\"].map(\n",
    "    lambda cat: cat if cat in [\"Circulatory\", \"Maternity\"] else \"other\").astype(\"category\")\n",
    "print(f\"There are {len(demodata)} observations in the data.\")\n",
    "print(demodata.dtypes)\n",
    "print(f\"The variable `Diagnosis_Category` has the categories {list(demodata[\"Diagnosis_Category\"].cat.categories)}\")\n",
    "print(f\"The variable `Gender` has the categories {list(demodata[\"Gender\"].cat.categories)}\")\n",
    "print(f\"The variable `Actual_Recoveries` takes the values {list(demodata[\"Actual_Recoveries\"].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:42.449826Z",
     "iopub.status.busy": "2024-07-29T18:36:42.448830Z",
     "iopub.status.idle": "2024-07-29T18:36:42.890048Z",
     "shell.execute_reply": "2024-07-29T18:36:42.890048Z",
     "shell.execute_reply.started": "2024-07-29T18:36:42.448830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>0.007608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.007293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>0.258492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>0.015333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.012845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  f\n",
       "Diagnosis_Category Gender          \n",
       "Circulatory        F       0.007608\n",
       "                   M       0.007293\n",
       "Maternity          F       0.258492\n",
       "other              F       0.015333\n",
       "                   M       0.012845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the space is: 5\n"
     ]
    }
   ],
   "source": [
    "# group the data to create a multi-index with unique 2-tuples\n",
    "grouped_df = demodata.groupby(\n",
    "    [\"Diagnosis_Category\", \"Gender\"], \n",
    "    observed=True)[\"Actual_Recoveries\"].agg(\n",
    "    f = \"mean\", n = \"count\")\n",
    "idx_2 = grouped_df.index\n",
    "print(idx_2.is_unique)\n",
    "f = grouped_df[\"f\"]\n",
    "display(f.to_frame())\n",
    "print(f\"Dimension of the space is: {len(idx_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, $f$ represents a function on the multi-index `idx_2` with unique tuples defined by `Diagnosis_Category` and `Gender`. Every 2-tuple from the two categories can take on any real value. This means that the dimension of the function space is exactly the number of unique tuples or - in Pandas terms - it is the length of the index. But, note that the index does not contain the tuple `(Maternity, M)`. None of the 6.4 million observations had this combination, for obvious, biological reasons. This is an example of impossible data, and the domain of definition is not a product. Hence, the inputs can never be independent. Knowing that the `Diagnosis_Category` is `Maternity`, tells you immediately something about `Gender`. Nevertheless, the interpretation as a space of functions and the calculation of dimension is not affected by this at all.\n",
    "\n",
    "To conclude:\n",
    "* A function with discrete domain is implemented as a Pandas series on a (multi-)index with unique tuples.\n",
    "* The dimension of the function space over this domain is the length of this index.\n",
    "\n",
    "Those functions which take on the value 1 for a single tuple of the index and 0 for all other tuples form a basis for this function space. This basis will be called the tuple-basis. For the dataset above, this would be a function which is 1 if the input is the tuple `(Circulatory, F)` and zero for all other inputs, another basis functions would be non-zero only for the input `(Circulatory, M)` and so on. In total 5 basis functions for the 5 possible tuples as input, which can replicate the values of every function defined on those 5 tuples by appropriate linear combinations.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_78b01\" style='display:inline'>\n",
       "  <caption>The tuple basis</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_78b01_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_78b01_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_78b01_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_78b01_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_78b01_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"index_name level1\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_78b01_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Circulatory</th>\n",
       "      <th id=\"T_78b01_level1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "      <td id=\"T_78b01_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_78b01_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78b01_level1_row1\" class=\"row_heading level1 row1\" >M</th>\n",
       "      <td id=\"T_78b01_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_78b01_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78b01_level0_row2\" class=\"row_heading level0 row2\" >Maternity</th>\n",
       "      <th id=\"T_78b01_level1_row2\" class=\"row_heading level1 row2\" >F</th>\n",
       "      <td id=\"T_78b01_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_78b01_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78b01_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"2\">other</th>\n",
       "      <th id=\"T_78b01_level1_row3\" class=\"row_heading level1 row3\" >F</th>\n",
       "      <td id=\"T_78b01_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_78b01_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78b01_level1_row4\" class=\"row_heading level1 row4\" >M</th>\n",
       "      <td id=\"T_78b01_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_78b01_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the tuple basis\n",
    "tuple_basis = pd.DataFrame(np.identity(len(idx_2)), index=idx_2)\n",
    "# this just for the joint display\n",
    "styled_A = tuple_basis.style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_A.set_caption(\"The tuple basis\")\n",
    "display_html(styled_A._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we need to introduce the probability measure $p_2$. In the grouping operation, the number of occurrences of the tuples in the original data was counted. Normalizing the total count to one, i.e. dividing by the total number of observations, defines the probability measure, i.e. the joint probability distribution of the tuples, respectively of the two inputs. The measure $p_2$ is defined on the same index as the functions, since there is one probability for each tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:42.891282Z",
     "iopub.status.busy": "2024-07-29T18:36:42.891282Z",
     "iopub.status.idle": "2024-07-29T18:36:42.901321Z",
     "shell.execute_reply": "2024-07-29T18:36:42.901321Z",
     "shell.execute_reply.started": "2024-07-29T18:36:42.891282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>0.055652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.079041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>0.487749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.373941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                p_2\n",
       "Diagnosis_Category Gender          \n",
       "Circulatory        F       0.055652\n",
       "                   M       0.079041\n",
       "Maternity          F       0.003617\n",
       "other              F       0.487749\n",
       "                   M       0.373941"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_2 = grouped_df[\"n\"] / grouped_df[\"n\"].sum()\n",
    "p_2.name = \"p_2\"\n",
    "p_2.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: A probability measure on a discrete space can also be implemented as a Pandas series on an index. Of course, in contrast to a general function, the values of the series have to be positive and sum to one over the index. Note, that we assume probabilities to be positive, i.e. we do not want unobserved/impossible combinations in the index. For this reason, the groupings above were always done with the option `observed=True`.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional distributions and expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning means replacing the index by a coarser one. In the example, going from an index with two levels, for the two inputs, to an index with a single level. Since the coarser index can no longer distinguish function values which differ in the dropped level, these different values are replaced by the single constant average, where the average is weighted by $p_2$. Conditioning of the constant function 1 defines conditional distributions, which are each of the two marginal distributions, since in each case only a single index is left.\n",
    "\n",
    "The coarsening, i.e. the transition from the 2-level index to the single level index, is again done by grouping followed by summing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:42.904330Z",
     "iopub.status.busy": "2024-07-29T18:36:42.904330Z",
     "iopub.status.idle": "2024-07-29T18:36:43.559415Z",
     "shell.execute_reply": "2024-07-29T18:36:43.556907Z",
     "shell.execute_reply.started": "2024-07-29T18:36:42.904330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a9baa\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9baa_level0_col0\" class=\"col_heading level0 col0\" >p_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9baa_level0_row0\" class=\"row_heading level0 row0\" >Circulatory</th>\n",
       "      <td id=\"T_a9baa_row0_col0\" class=\"data row0 col0\" >0.134693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9baa_level0_row1\" class=\"row_heading level0 row1\" >Maternity</th>\n",
       "      <td id=\"T_a9baa_row1_col0\" class=\"data row1 col0\" >0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9baa_level0_row2\" class=\"row_heading level0 row2\" >other</th>\n",
       "      <td id=\"T_a9baa_row2_col0\" class=\"data row2 col0\" >0.861690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9e507\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9e507_level0_col0\" class=\"col_heading level0 col0\" >p_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e507_level0_row0\" class=\"row_heading level0 row0\" >F</th>\n",
       "      <td id=\"T_9e507_row0_col0\" class=\"data row0 col0\" >0.547018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e507_level0_row1\" class=\"row_heading level0 row1\" >M</th>\n",
       "      <td id=\"T_9e507_row1_col0\" class=\"data row1 col0\" >0.452982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine the two marginal distributions, one for ach level of the index\n",
    "p_A = p_2.groupby(\"Diagnosis_Category\", observed=True).sum()\n",
    "p_A.name = \"p_A\"\n",
    "p_B = p_2.groupby(\"Gender\", observed=True).sum()\n",
    "p_B.name = \"p_B\"\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = p_A.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = p_B.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_()\n",
    "             + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional expectation of a non-constant function $f$ works in the same way. We only have to incorporate the $f$ values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.564420Z",
     "iopub.status.busy": "2024-07-29T18:36:43.562420Z",
     "iopub.status.idle": "2024-07-29T18:36:43.577837Z",
     "shell.execute_reply": "2024-07-29T18:36:43.577837Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.564420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0b74e\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b74e_level0_col0\" class=\"col_heading level0 col0\" >f_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b74e_level0_row0\" class=\"row_heading level0 row0\" >Circulatory</th>\n",
       "      <td id=\"T_0b74e_row0_col0\" class=\"data row0 col0\" >0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b74e_level0_row1\" class=\"row_heading level0 row1\" >Maternity</th>\n",
       "      <td id=\"T_0b74e_row1_col0\" class=\"data row1 col0\" >0.258492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b74e_level0_row2\" class=\"row_heading level0 row2\" >other</th>\n",
       "      <td id=\"T_0b74e_row2_col0\" class=\"data row2 col0\" >0.014253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e1eb7\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e1eb7_level0_col0\" class=\"col_heading level0 col0\" >f_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e1eb7_level0_row0\" class=\"row_heading level0 row0\" >F</th>\n",
       "      <td id=\"T_e1eb7_row0_col0\" class=\"data row0 col0\" >0.016155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1eb7_level0_row1\" class=\"row_heading level0 row1\" >M</th>\n",
       "      <td id=\"T_e1eb7_row1_col0\" class=\"data row1 col0\" >0.011876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_weighted = f * p_2\n",
    "f_A = f_weighted.groupby(\"Diagnosis_Category\", observed=True).sum()\n",
    "f_A = f_A / p_A\n",
    "f_A.name = \"f_A\"\n",
    "f_B = f_weighted.groupby(\"Gender\", observed=True).sum()\n",
    "f_B = f_B / p_B\n",
    "f_B.name = \"f_B\"\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = f_A.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = f_B.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_()\n",
    "             + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since conditional expectations are random variables in their own right, we can calculate their expected values. As a sanity check on the calculations this far, we calculate the expectation of $f$ in three different ways:\n",
    "1. From the original demo dataset using `mean`. The Pandas function `mean` is the unweighted, arithmetic average. The according measure is the uniform measure, which reflects the iid nature of the original data.\n",
    "2. From the aggregated function with unique index using the measure $p_2$, which results from aggregation of iid observations. \n",
    "3. From the two marginal distributions with the appropriate conditional expectations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block is just a quick sanity check, to make sure everything works as expected and the different ways to calculate the expected value of the `Actual_Recoveries` all agree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.579847Z",
     "iopub.status.busy": "2024-07-29T18:36:43.578847Z",
     "iopub.status.idle": "2024-07-29T18:36:43.592907Z",
     "shell.execute_reply": "2024-07-29T18:36:43.592907Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.579847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014216733536931153 0.014216733536931155 0.014216733536931155 0.014216733536931155\n"
     ]
    }
   ],
   "source": [
    "f_1 = demodata[\"Actual_Recoveries\"].mean()\n",
    "f_2 = (f * p_2).sum()\n",
    "f_3_A = (f_A * p_A).sum()\n",
    "f_3_B = (f_B * p_B).sum()\n",
    "\n",
    "print(f_1, f_2, f_3_A, f_3_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a conditional expectation reduces the index, the resulting function is obviously defined on a different index than the original one. Just compare the Pandas series for $f_A$ or $f_B$ with the one for $f$ in the examples above. This is a problem since our ultimate goal is to split a function into components, such that the components sum up to the original function. Such a decomposition can only make sense, if all components are defined on the same domain as the original function. This means we need to find a way to embed functions on a coarse index, i.e. with few levels, back into an index with more levels. In Pandas, this can be accomplished by the broadcasting or reindexing mechanism.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.593914Z",
     "iopub.status.busy": "2024-07-29T18:36:43.593914Z",
     "iopub.status.idle": "2024-07-29T18:36:43.605013Z",
     "shell.execute_reply": "2024-07-29T18:36:43.605013Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.593914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_658ae\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_658ae_level0_col0\" class=\"col_heading level0 col0\" >f_A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_658ae_level0_row0\" class=\"row_heading level0 row0\" >Circulatory</th>\n",
       "      <td id=\"T_658ae_row0_col0\" class=\"data row0 col0\" >0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_658ae_level0_row1\" class=\"row_heading level0 row1\" >Maternity</th>\n",
       "      <td id=\"T_658ae_row1_col0\" class=\"data row1 col0\" >0.258492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_658ae_level0_row2\" class=\"row_heading level0 row2\" >other</th>\n",
       "      <td id=\"T_658ae_row2_col0\" class=\"data row2 col0\" >0.014253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d09ee\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d09ee_level0_col0\" class=\"col_heading level0 col0\" >broadcast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"index_name level1\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d09ee_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Circulatory</th>\n",
       "      <th id=\"T_d09ee_level1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "      <td id=\"T_d09ee_row0_col0\" class=\"data row0 col0\" >0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d09ee_level1_row1\" class=\"row_heading level1 row1\" >M</th>\n",
       "      <td id=\"T_d09ee_row1_col0\" class=\"data row1 col0\" >0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d09ee_level0_row2\" class=\"row_heading level0 row2\" >Maternity</th>\n",
       "      <th id=\"T_d09ee_level1_row2\" class=\"row_heading level1 row2\" >F</th>\n",
       "      <td id=\"T_d09ee_row2_col0\" class=\"data row2 col0\" >0.258492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d09ee_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"2\">other</th>\n",
       "      <th id=\"T_d09ee_level1_row3\" class=\"row_heading level1 row3\" >F</th>\n",
       "      <td id=\"T_d09ee_row3_col0\" class=\"data row3 col0\" >0.014253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d09ee_level1_row4\" class=\"row_heading level1 row4\" >M</th>\n",
       "      <td id=\"T_d09ee_row4_col0\" class=\"data row4 col0\" >0.014253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# broadcast f_A back to the original index\n",
    "# for whatever reason this does not work for a CategoricalIndex \n",
    "# so we need a cast to \"string\". \n",
    "tmp = pd.Series(f_A, index=f_A.index.astype(str))\n",
    "f_A_broadcast = tmp.reindex(index=idx_2, level=\"Diagnosis_Category\")\n",
    "f_A_broadcast.name = \"broadcast\"\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = f_A.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = f_A_broadcast.to_frame().style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_()\n",
    "             + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This broadcasting is just the concrete implementation of the conceptional identification between a function with a single input, and a function of two inputs, which is constant with respect to one of its inputs. In the example above, the broadcasted $f_A$ is constant with respect to `Gender`. It is easy to verify, that the conditional expectation of the broadcast function with respect to `Diagnosis_Category` is again the original $f_A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, that the probability measure $p_2$ defines an inner product on its space of random variables with finite variance. The inner product $\\langle \\cdot, \\cdot\\rangle$ between $h=h(A,B)$ and $g=g(A,B)$ is the expected value with respect to $p_2$ of their product, i.e.\n",
    "$$\\langle g, h\\rangle=\\mathbb{E}_{(A,B)}[g \\cdot h].$$\n",
    "As an immediate consequence, probabilistic notions can be directly translated into geometric ones, and vice versa. For zero mean functions $g$ and $h$ we will use  that:\n",
    "* The variance of $g$ is equal to the square norm $\\| g \\|^2 = \\langle g, g\\rangle$.\n",
    "* $g$ and $h$ are uncorrelated if and only if $g$ and $h$ are orthogonal $\\langle g, h\\rangle = 0$ or $g\\perp h.$\n",
    "\n",
    "But, before we are able to fully use numerical linear algebra from numpy or scipy, we need to resolve one remaining issue. The standard numerical routines assume coordinates, for which the inner product is the standard Euclidean one, or, equivalently, that the basis vectors are orthonormal. It is convenient to use the tuple-basis introduced above. But this basis is not orthonormal. As the following computation of the Gram matrix shows. Recall that the Gram matrix is the matrix $G$ made up of all inner products of the basis vectors: $G_{ij} = \\mathbb{E}[b_i b_j]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.607037Z",
     "iopub.status.busy": "2024-07-29T18:36:43.606023Z",
     "iopub.status.idle": "2024-07-29T18:36:43.624040Z",
     "shell.execute_reply": "2024-07-29T18:36:43.624040Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.607037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4bde7\" style='display:inline'>\n",
       "  <caption>Coordinates of tuple basis vectors</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4bde7_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_4bde7_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_4bde7_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_4bde7_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_4bde7_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"index_name level1\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4bde7_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Circulatory</th>\n",
       "      <th id=\"T_4bde7_level1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "      <td id=\"T_4bde7_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_4bde7_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bde7_level1_row1\" class=\"row_heading level1 row1\" >M</th>\n",
       "      <td id=\"T_4bde7_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_4bde7_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bde7_level0_row2\" class=\"row_heading level0 row2\" >Maternity</th>\n",
       "      <th id=\"T_4bde7_level1_row2\" class=\"row_heading level1 row2\" >F</th>\n",
       "      <td id=\"T_4bde7_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_4bde7_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bde7_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"2\">other</th>\n",
       "      <th id=\"T_4bde7_level1_row3\" class=\"row_heading level1 row3\" >F</th>\n",
       "      <td id=\"T_4bde7_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_4bde7_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bde7_level1_row4\" class=\"row_heading level1 row4\" >M</th>\n",
       "      <td id=\"T_4bde7_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_4bde7_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8863a\" style='display:inline'>\n",
       "  <caption>Gram Matrix</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8863a_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_8863a_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_8863a_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_8863a_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_8863a_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8863a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8863a_row0_col0\" class=\"data row0 col0\" >0.055652</td>\n",
       "      <td id=\"T_8863a_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8863a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8863a_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row1_col1\" class=\"data row1 col1\" >0.079041</td>\n",
       "      <td id=\"T_8863a_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8863a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8863a_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row2_col2\" class=\"data row2 col2\" >0.003617</td>\n",
       "      <td id=\"T_8863a_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8863a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8863a_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row3_col3\" class=\"data row3 col3\" >0.487749</td>\n",
       "      <td id=\"T_8863a_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8863a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8863a_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_8863a_row4_col4\" class=\"data row4 col4\" >0.373941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the tuple basis\n",
    "tuple_basis = pd.DataFrame(np.identity(len(idx_2)), index=idx_2)\n",
    "\n",
    "# create Gram-matrix\n",
    "gramdf = pd.DataFrame(0.0, index=range(5), columns=range(5))\n",
    "for (ii,jj) in itertools.combinations_with_replacement(range(5),2):\n",
    "    gramdf.loc[ii,jj] = (tuple_basis[ii] * tuple_basis[jj] * p_2).sum()\n",
    "    gramdf.loc[jj,ii] = gramdf.loc[ii,jj]\n",
    "\n",
    "# this just for the joint display\n",
    "styled_A = tuple_basis.style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_A.set_caption(\"Coordinates of tuple basis vectors\")\n",
    "styled_B = gramdf.style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B.set_caption(\"Gram Matrix\")\n",
    "display_html(styled_A._repr_html_() + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the tuple basis is orthogonal but not normalised. Since a basis vector $b_i$ has squared length\n",
    "$$\\|b_i\\|^2 = \\mathbb{E}[b_i b_i] = \\mathbb{E}[b_i] = p_i,$$\n",
    "where the fact is used that $b_i$ takes only the values 0 and 1 and, accordingly $b_i^2=b_i.$  \n",
    "To obtain normalised basis vectors $\\tilde{b}_i$ we need to scale them as $\\tilde{b}_i = \\frac{1}{\\sqrt{p_i}}b_i.$ Since coordinates transform with the inverse we have the following rules:\n",
    "* To transform tuple coordinates to normalised coordinates, multiply tuple coordinates by $\\sqrt{p_i}$.\n",
    "* To transform normalised coordinates to tuple coordinates, multiply normalised coordinates by $\\frac{1}{\\sqrt{p_i}}$.\n",
    "\n",
    "After this transformation, one can use all standard linear algebra routines, as found in numpy or scipy, using the new coordinates. As an admittedly obvious example, here the calculation of the Gram matrix again, but this time only using numpy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.626047Z",
     "iopub.status.busy": "2024-07-29T18:36:43.625047Z",
     "iopub.status.idle": "2024-07-29T18:36:43.640115Z",
     "shell.execute_reply": "2024-07-29T18:36:43.640115Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.626047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05565198, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.07904095, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.00361746, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.48774883, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37394077]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform tuple basis to normalised basis\n",
    "norm_basis = tuple_basis.mul(np.sqrt(p_2), axis=0)\n",
    "# do plain vanilla numpy matrix computation\n",
    "tmpmat = norm_basis.to_numpy()\n",
    "tmpmat @ tmpmat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of the correlated H-statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define $\\mathscr{V}_2$ as the space of all random variables, which can be written as bivariate functions with inputs $(A,B)$. The goal now is to explicitely determine or calculate the subspaces \n",
    "* $\\mathscr{V}_0$: the space of constant functions\n",
    "* $\\mathscr{V}_1$: a space spanned by all univariate functions \n",
    "* and $V_\\text{inter}$ a space of functions with interactions \n",
    "such that\n",
    "$$ \\mathscr{V}_2=\\mathscr{V}_0 \\boxplus \\mathscr{V}_1 \\boxplus \\mathscr{V_\\text{inter}},$$\n",
    "where the operator $\\boxplus$ means direct, orthogonal sum. This decomposition allows in turn to write any function $f_2$ from $\\mathscr{V}_2$ as \n",
    "$$f_2=f_0 + f_1 + f_\\mathrm{{inter}}$$\n",
    "with the properties\n",
    "1. The summands $f_0$, $f_1$ and $f_\\text{inter}$ are uniquely defined\n",
    "2. The summands $f_1$ and $f_\\text{inter} = f_2 - f_0 - f_1$ are uncorrelated.\n",
    "3. $f_1$ is the best approximation of $f_2$ in least squares which can be written as a linear combination of univariate functions.\n",
    "\n",
    "These three properties are exactly the properties needed from the original FANOVA decomposition to motivate the definition of the H-statistic. This means we can define the H-statistic in terms of the decomposition above in the same way as before, i.e. as\n",
    "$$ H=\\frac{\\mathbb{V}[f_2 - f_0 - f_1]}{\\mathbb{V}[f_2]}.$$\n",
    "\n",
    "The only difference to the independent case is, that we cannot further decompose $\\mathscr{V}_1$ into orthogonal subspaces of univariate functions. Since $A$ and $B$ are dependent, those subspaces will not be orthogonal. But this is not really necessary to define the H-statistic.\n",
    "\n",
    "The only things left to do before we can compute the correlated H-statistic are the definitions of $\\mathscr{V}_1$ and $\\mathscr{V}_\\text{inter}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of $\\mathscr{V}_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The space $\\mathscr{V}_1$ will be defined by providing a set of basis vectors. We start with the tuple-basis for the spaces defined on input $A$, called $\\mathscr{V}_A$ and input $B$, $\\mathscr{V}_B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.642123Z",
     "iopub.status.busy": "2024-07-29T18:36:43.641123Z",
     "iopub.status.idle": "2024-07-29T18:36:43.654524Z",
     "shell.execute_reply": "2024-07-29T18:36:43.653505Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.642123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_63d2b\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63d2b_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_63d2b_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_63d2b_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Diagnosis_Category</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63d2b_level0_row0\" class=\"row_heading level0 row0\" >Circulatory</th>\n",
       "      <td id=\"T_63d2b_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_63d2b_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_63d2b_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63d2b_level0_row1\" class=\"row_heading level0 row1\" >Maternity</th>\n",
       "      <td id=\"T_63d2b_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_63d2b_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_63d2b_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63d2b_level0_row2\" class=\"row_heading level0 row2\" >other</th>\n",
       "      <td id=\"T_63d2b_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_63d2b_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_63d2b_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_71f6e\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71f6e_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_71f6e_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Gender</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71f6e_level0_row0\" class=\"row_heading level0 row0\" >F</th>\n",
       "      <td id=\"T_71f6e_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_71f6e_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71f6e_level0_row1\" class=\"row_heading level0 row1\" >M</th>\n",
       "      <td id=\"T_71f6e_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_71f6e_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuple_basis_A = pd.DataFrame(np.identity(len(f_A.index)), index=f_A.index.astype(str))\n",
    "tuple_basis_B = pd.DataFrame(np.identity(len(f_B.index)), index=f_B.index.astype(str))\n",
    "\n",
    "# this is just for the joint display\n",
    "styled_A = tuple_basis_A.style.set_table_attributes(\"style='display:inline'\")\n",
    "styled_B = tuple_basis_B.style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styled_A._repr_html_() + styled_B._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two bases are now broadcast to $\\mathscr{V}_2$, but there is a catch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.656523Z",
     "iopub.status.busy": "2024-07-29T18:36:43.655522Z",
     "iopub.status.idle": "2024-07-29T18:36:43.675325Z",
     "shell.execute_reply": "2024-07-29T18:36:43.675325Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.656523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Diagnosis_Category</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Diagnosis_Category           Gender     \n",
       "                                           0    1    2      0    1\n",
       "Diagnosis_Category Gender                                         \n",
       "Circulatory        F                     1.0  0.0  0.0    1.0  0.0\n",
       "                   M                     1.0  0.0  0.0    0.0  1.0\n",
       "Maternity          F                     0.0  1.0  0.0    1.0  0.0\n",
       "other              F                     0.0  0.0  1.0    1.0  0.0\n",
       "                   M                     0.0  0.0  1.0    0.0  1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_basis_1 = pd.concat([tuple_basis_A.reindex(index=idx_2, level=0), tuple_basis_B.reindex(index=idx_2, level=1)],\n",
    "                          keys=[\"Diagnosis_Category\", \"Gender\"],axis=1)\n",
    "tuple_basis_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After broadcasting, the vectors are no longer linearly independent. The sum of the first three is the constant (all ones) vector, and the sum of the last two is constant again. Furthermore, we need to treat the constant vector separately, since the space of constants shall get its own space, $\\mathscr{V}_0$. This is just a manifestation of the \"drop 1\" requirement for one hot encoding. So we need to drop on vector from each of tuple_basis_A and _B. Here we implement \"drop first\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.677332Z",
     "iopub.status.busy": "2024-07-29T18:36:43.677332Z",
     "iopub.status.idle": "2024-07-29T18:36:43.695521Z",
     "shell.execute_reply": "2024-07-29T18:36:43.694512Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.677332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          const Diagnosis_Category      Gender\n",
       "                              0                  0    1      0\n",
       "Diagnosis_Category Gender                                     \n",
       "Circulatory        F          1                0.0  0.0    0.0\n",
       "                   M          1                0.0  0.0    1.0\n",
       "Maternity          F          1                1.0  0.0    0.0\n",
       "other              F          1                0.0  1.0    0.0\n",
       "                   M          1                0.0  1.0    1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_basis_A = pd.DataFrame(np.identity(len(f_A.index))[:,1:], index=f_A.index.astype(str))\n",
    "tuple_basis_B = pd.DataFrame(np.identity(len(f_B.index))[:,1:], index=f_B.index.astype(str))\n",
    "const = pd.Series(1, index=idx_2)\n",
    "tuple_basis_01 = pd.concat([const, tuple_basis_A.reindex(index=idx_2, level=0), tuple_basis_B.reindex(index=idx_2, level=1)],\n",
    "                          keys=[\"const\", \"Diagnosis_Category\", \"Gender\"], axis=1)\n",
    "tuple_basis_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection shows that the vectors above are linearly independent, i.e. they form a basis. Together with the constant vector, we are still able to recover the dropped vectors with tuples (\"Diagnosis_Category\", 2) and (\"Gender\", 1) from above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.696522Z",
     "iopub.status.busy": "2024-07-29T18:36:43.696522Z",
     "iopub.status.idle": "2024-07-29T18:36:43.709175Z",
     "shell.execute_reply": "2024-07-29T18:36:43.709175Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.696522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0    1\n",
       "Diagnosis_Category Gender          \n",
       "Circulatory        F       1.0  1.0\n",
       "                   M       1.0  0.0\n",
       "Maternity          F       0.0  1.0\n",
       "other              F       0.0  1.0\n",
       "                   M       0.0  0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_0 = (tuple_basis_01[(\"const\", 0)] \n",
    "        - tuple_basis_01[(\"Diagnosis_Category\", 0)] - tuple_basis_01[(\"Diagnosis_Category\", 1)])\n",
    "g_1 = (tuple_basis_01[(\"const\", 0)] - tuple_basis_01[(\"Gender\", 0)])\n",
    "pd.concat([dc_0, g_1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly count the dimensions of the spaces, set $\\text{dim}\\mathscr{V}_2 =\\text{len}\\, (idx_2) = n$ and define $c_A$ and $c_B$ as the number of levels of $A$ respectively $B$. Since the decomposition of the subspaces is a direct sum, their dimensions add up to the total dimension:\n",
    "$$ \\text{dim}\\mathscr{V}_2 = \\text{dim}\\mathscr{V}_0 + \\text{dim}\\mathscr{V}_1 + \\text{dim}\\mathscr{V}_\\text{inter}.$$\n",
    "By construction of the index, $ n\\geq 1$ and $\\text{dim}\\,\\mathscr{V}_0=1$. If the number of observed tuples is large enough, i.e. if $n-1 \\geq c_A + c_B - 2$ then \n",
    "$$ \\text{dim}\\mathscr{V}_1 = c_A + c_B - 2 \\quad\\text{ and }\\quad \\text{dim}\\mathscr{V}_\\text{inter} = n - 1 - (c_A + c_B - 2).$$\n",
    "If the index becomes smaller, interactions are not possible. If $n - 1 \\leq (c_A + c_B - 2)$ then\n",
    "$$ \\text{dim}\\mathscr{V}_1 = n-1 \\quad\\text{ and }\\quad \\text{dim}\\mathscr{V}_\\text{inter} = 0.$$ \n",
    "In our example $n=5$, $c_A = 3$ and $c_B=2$, so that $c_A + c_B - 2 = 3 \\leq 4 = n - 1$ and we can conclude\n",
    "$$ \\text{dim}\\mathscr{V}_1 = 3 \\quad\\text{ and }\\quad \\text{dim}\\mathscr{V}_\\text{inter} = 1.$$\n",
    "\n",
    "When constructing the basis of $\\mathscr{V}_1$ in practice, it does not matter how we choose the basis vectors. If the number is OK and if they are linearly independent, we are fine. Here, we just take the joint basis for $\\mathscr{V}_0 + \\mathscr{V}_1$ from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.711184Z",
     "iopub.status.busy": "2024-07-29T18:36:43.710183Z",
     "iopub.status.idle": "2024-07-29T18:36:43.723978Z",
     "shell.execute_reply": "2024-07-29T18:36:43.723978Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.711184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          const Diagnosis_Category      Gender\n",
       "                              0                  0    1      0\n",
       "Diagnosis_Category Gender                                     \n",
       "Circulatory        F          1                0.0  0.0    0.0\n",
       "                   M          1                0.0  0.0    1.0\n",
       "Maternity          F          1                1.0  0.0    0.0\n",
       "other              F          1                0.0  1.0    0.0\n",
       "                   M          1                0.0  1.0    1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_basis_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of $\\mathscr{V}_\\text{Inter}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fast and numerically stable way to construct the orthogonal complement is the full QR-decomposition, as provided by the function `scipy.linalg.qr`. As mentioned above, we need to perform a change of coordinates before, and after application of the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.725986Z",
     "iopub.status.busy": "2024-07-29T18:36:43.724987Z",
     "iopub.status.idle": "2024-07-29T18:36:43.737243Z",
     "shell.execute_reply": "2024-07-29T18:36:43.737243Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.725986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformation of normalised basis and extraction of the numpy array\n",
    "A = tuple_basis_01.multiply(np.sqrt(p_2), axis=0).to_numpy()\n",
    "Q, R = linalg.qr(A)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition of the QR decomposition, $Q$ is an orthonormal basis of $\\mathscr{V}_2$ where the first four vectors are a basis for the column space of $A$, which is $\\mathscr{V}_0 + \\mathscr{V}_1$ and the last one a basis for the orthogonal complement, i.e. $\\mathscr{V}_\\text{Inter}.$ Of course, this is in normalised coordinates, so we have to transform this vector back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.739251Z",
     "iopub.status.busy": "2024-07-29T18:36:43.738252Z",
     "iopub.status.idle": "2024-07-29T18:36:43.749153Z",
     "shell.execute_reply": "2024-07-29T18:36:43.749153Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.739251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Interaction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Circulatory</th>\n",
       "      <th>F</th>\n",
       "      <td>-3.022426e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>2.128062e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maternity</th>\n",
       "      <th>F</th>\n",
       "      <td>2.460586e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">other</th>\n",
       "      <th>F</th>\n",
       "      <td>3.448579e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>-4.498146e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Interaction\n",
       "Diagnosis_Category Gender              \n",
       "Circulatory        F      -3.022426e+00\n",
       "                   M       2.128062e+00\n",
       "Maternity          F       2.460586e-15\n",
       "other              F       3.448579e-01\n",
       "                   M      -4.498146e-01"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_basis_inter = pd.DataFrame(Q[:,-1:], index=idx_2, columns=[\"Interaction\"]).multiply(1 / np.sqrt(p_2), axis=0)\n",
    "tuple_basis_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good thing to verify the orthogonality of the subspaces. The following calculation shows $\\mathscr{V}_0 + \\mathscr{V}_1\\perp $\\mathscr{V}_\\text{Inter}$. The result is shown in full machine precision, i.e. without rounding. This is just to remind the reader, that operations on large matrices may create numerical issues. But in our toy example the results are reassuringly \"orthogonal\", i.e. zero up to machine precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.751161Z",
     "iopub.status.busy": "2024-07-29T18:36:43.750198Z",
     "iopub.status.idle": "2024-07-29T18:36:43.757018Z",
     "shell.execute_reply": "2024-07-29T18:36:43.757018Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.751161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1102230246251565e-16\n",
      "8.901069979099821e-18\n",
      "0.0\n",
      "-8.326672684688674e-17\n"
     ]
    }
   ],
   "source": [
    "for col in tuple_basis_01.columns:\n",
    "    print((tuple_basis_01[col] * tuple_basis_inter[\"Interaction\"] * p_2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not explicitely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of the statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any function defined on the index can no be decomposed by expressing it in terms of the basis. This can be done using $Q$ in normalised coordinates or using the transformed vectors in the tuple-coordinates. It is slightly more efficient to do this directly in numpy using normalised coordinates. Here we decompose the raw data vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.759534Z",
     "iopub.status.busy": "2024-07-29T18:36:43.758026Z",
     "iopub.status.idle": "2024-07-29T18:36:43.764227Z",
     "shell.execute_reply": "2024-07-29T18:36:43.764227Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.759534Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform f to normalised coordinates\n",
    "fnc = f * np.sqrt(p_2)\n",
    "# find coefficients wrt to basis Q\n",
    "x = linalg.solve(Q,fnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates relate directly to the subspaces. The coefficient of $R$ ensures the correct sign of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.768234Z",
     "iopub.status.busy": "2024-07-29T18:36:43.768234Z",
     "iopub.status.idle": "2024-07-29T18:36:43.773671Z",
     "shell.execute_reply": "2024-07-29T18:36:43.773671Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.768234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variance is 0.000223\n",
      "      thereof 99.9% additive and 0.1% interaction \n"
     ]
    }
   ],
   "source": [
    "dim_bas = tuple_basis_01.shape[1]\n",
    "f_mean = R[0,0] * x[0]\n",
    "# Variance of f\n",
    "V = linalg.norm(x[1:])**2\n",
    "V_1 = linalg.norm(x[1:dim_bas])**2\n",
    "V_inter = linalg.norm(x[dim_bas:])**2\n",
    "Hcorr = V_inter / V\n",
    "print(f\"Total variance is {np.round(V,6)}\\n\\\n",
    "      thereof {np.round(V_1 / V *100,1)}% additive and {np.round(V_inter/V*100,1)}% interaction \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, one can check correctness by comparing some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T18:36:43.775678Z",
     "iopub.status.busy": "2024-07-29T18:36:43.774679Z",
     "iopub.status.idle": "2024-07-29T18:36:43.780484Z",
     "shell.execute_reply": "2024-07-29T18:36:43.780484Z",
     "shell.execute_reply.started": "2024-07-29T18:36:43.775678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "f_mean_alt = (f * p_2).sum()\n",
    "print(abs(f_mean - f_mean_alt) < 1e-15)\n",
    "V_alt = (f**2 * p_2).sum() - f_mean_alt**2\n",
    "print(abs(V - V_alt) < 1e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the basis and the embedding space are very high dimensional, the explicit computation and storage of a $(n,n)$ matrix is no longer  feasible. In that case, the least squares solution to the equation $Ax=f$ with $A$ the normalized tuple basis and $f$ the normalized function, is a very efficient alternative. This function is provided in `scipy.linalg` as `lstsq`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling, run time and memory considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this example is quite limited in scope, it remains a fair question how this approach scales to real world problem sizes. The brief answer is: Very well indeed. To support this statement, note that there are only two drivers of computational resources.\n",
    "\n",
    "The first driver is the sheer number of pairs in the input, which scale as $d^2$. Second is the dimension of the respective spaces. But both can be handled efficiently, as the worked example in \"exp_anova\", with 21 inputs, and some of them with high cardinality, shows.  \n",
    "\n",
    "The size of the dataset just matters for the fitting of the model, and the prediction, i.e. the construction of $f$. After this is done, data will be aggregated to observed tuples. This is why the total size of the data (in our case roughly 6.4 million observations) does not matter, or does matter only very slightly as this aggregation is done in Pandas very efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLTD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
